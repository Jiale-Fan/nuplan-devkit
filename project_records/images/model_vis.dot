digraph {
	graph [size="455.4,455.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139617218720128 [label="
 (1, 16, 3)" fillcolor=darkolivegreen1]
	139618681380816 [label="ViewBackward
-------------------
self_sizes: (1, 48)"]
	139618681379280 -> 139618681380816
	139618681379280 -> 139617219994816 [dir=none]
	139617219994816 [label="mat1
 (1, 128)" fillcolor=orange]
	139618681379280 -> 139617257532416 [dir=none]
	139617257532416 [label="mat2
 (128, 48)" fillcolor=orange]
	139618681379280 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :      (128, 48)
mat2_strides:       (1, 128)"]
	139618681380672 -> 139618681379280
	139617202859456 [label="model._mlp.4.bias
 (48)" fillcolor=lightblue]
	139617202859456 -> 139618681380672
	139618681380672 [label=AccumulateGrad]
	139618452679024 -> 139618681379280
	139618452679024 -> 139617229773824 [dir=none]
	139617229773824 [label="self
 (1, 128)" fillcolor=orange]
	139618452679024 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139618452679888 -> 139618452679024
	139618452679888 -> 139617236088064 [dir=none]
	139617236088064 [label="mat1
 (1, 128)" fillcolor=orange]
	139618452679888 -> 139617234548800 [dir=none]
	139617234548800 [label="mat2
 (128, 128)" fillcolor=orange]
	139618452679888 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618452678784 -> 139618452679888
	139617202859136 [label="model._mlp.2.bias
 (128)" fillcolor=lightblue]
	139617202859136 -> 139618452678784
	139618452678784 [label=AccumulateGrad]
	139618452679552 -> 139618452679888
	139618452679552 -> 139617230835264 [dir=none]
	139617230835264 [label="self
 (1, 128)" fillcolor=orange]
	139618452679552 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139618452676816 -> 139618452679552
	139618452676816 -> 139617230834944 [dir=none]
	139617230834944 [label="mat1
 (1, 128)" fillcolor=orange]
	139618452676816 -> 139617200340288 [dir=none]
	139617200340288 [label="mat2
 (128, 128)" fillcolor=orange]
	139618452676816 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617231538112 -> 139618452676816
	139617202858496 [label="model._mlp.0.bias
 (128)" fillcolor=lightblue]
	139617202858496 -> 139617231538112
	139617231538112 [label=AccumulateGrad]
	139617231539168 -> 139618452676816
	139617231539168 [label="ViewBackward
------------------
self_sizes: (128,)"]
	139617231536528 -> 139617231539168
	139617231536528 [label="CatBackward
-----------
dim: 0"]
	139619597246576 -> 139617231536528
	139619597246576 [label="SelectBackward
---------------------
dim       :         0
index     :         0
self_sizes: (68, 128)"]
	139619599444528 -> 139619597246576
	139619599444528 -> 139617200337088 [dir=none]
	139617200337088 [label="result
 (68, 128)" fillcolor=orange]
	139619599444528 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139619599445872 -> 139619599444528
	139619599445872 [label="AddBackward0
------------
alpha: 1"]
	139619599443568 -> 139619599445872
	139619599443568 -> 139617262766784 [dir=none]
	139617262766784 [label="mat1
 (68, 128)" fillcolor=orange]
	139619599443568 -> 139617199991680 [dir=none]
	139617199991680 [label="mat2
 (128, 128)" fillcolor=orange]
	139619599443568 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139619599444336 -> 139619599443568
	139617202858176 [label="model.actor2actor_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139617202858176 -> 139619599444336
	139619599444336 [label=AccumulateGrad]
	139619599443472 -> 139619599443568
	139619599443472 -> 139617220243136 [dir=none]
	139617220243136 [label="result
 (68, 128)" fillcolor=orange]
	139619599443472 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617219602128 -> 139619599443472
	139617219602128 -> 139617236264576 [dir=none]
	139617236264576 [label="bias
 (128)" fillcolor=orange]
	139617219602128 -> 139617228389120 [dir=none]
	139617228389120 [label="input
 (68, 128)" fillcolor=orange]
	139617219602128 -> 139617228388416 [dir=none]
	139617228388416 [label="result1
 (68, 1)" fillcolor=orange]
	139617219602128 -> 139617228389248 [dir=none]
	139617228389248 [label="result2
 (68, 1)" fillcolor=orange]
	139617219602128 -> 139617228388096 [dir=none]
	139617228388096 [label="weight
 (128)" fillcolor=orange]
	139617219602128 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617219601600 -> 139617219602128
	139617219601600 -> 139617230853824 [dir=none]
	139617230853824 [label="index
 (590)" fillcolor=orange]
	139617219601600 -> 139617230855360 [dir=none]
	139617230855360 [label="source
 (590, 128)" fillcolor=orange]
	139617219601600 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618677204256 -> 139617219601600
	139618677204256 [label=CloneBackward]
	139618677204448 -> 139618677204256
	139618677204448 -> 139617230854848 [dir=none]
	139617230854848 [label="result
 (68, 128)" fillcolor=orange]
	139618677204448 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618677204880 -> 139618677204448
	139618677204880 -> 139617199989632 [dir=none]
	139617199989632 [label="mat1
 (68, 128)" fillcolor=orange]
	139618677204880 -> 139617199989376 [dir=none]
	139617199989376 [label="mat2
 (128, 128)" fillcolor=orange]
	139618677204880 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618677205312 -> 139618677204880
	139617202856000 [label="model.actor2actor_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617202856000 -> 139618677205312
	139618677205312 [label=AccumulateGrad]
	139619599445632 -> 139618677204880
	139619599445632 -> 139618562577792 [dir=none]
	139618562577792 [label="result
 (68, 128)" fillcolor=orange]
	139619599445632 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618677205936 -> 139619599445632
	139618677205936 [label="AddBackward0
------------
alpha: 1"]
	139618677206752 -> 139618677205936
	139618677206752 -> 139617215563712 [dir=none]
	139617215563712 [label="mat1
 (68, 128)" fillcolor=orange]
	139618677206752 -> 139618562579712 [dir=none]
	139618562579712 [label="mat2
 (128, 128)" fillcolor=orange]
	139618677206752 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618677206944 -> 139618677206752
	139617200675840 [label="model.actor2actor_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139617200675840 -> 139618677206944
	139618677206944 [label=AccumulateGrad]
	139618677203968 -> 139618677206752
	139618677203968 -> 139617215563008 [dir=none]
	139617215563008 [label="result
 (68, 128)" fillcolor=orange]
	139618677203968 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236111616 -> 139618677203968
	139617236111616 -> 139617235953216 [dir=none]
	139617235953216 [label="bias
 (128)" fillcolor=orange]
	139617236111616 -> 139617235955072 [dir=none]
	139617235955072 [label="input
 (68, 128)" fillcolor=orange]
	139617236111616 -> 139617235954240 [dir=none]
	139617235954240 [label="result1
 (68, 1)" fillcolor=orange]
	139617236111616 -> 139617235953024 [dir=none]
	139617235953024 [label="result2
 (68, 1)" fillcolor=orange]
	139617236111616 -> 139617235952256 [dir=none]
	139617235952256 [label="weight
 (128)" fillcolor=orange]
	139617236111616 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617236113248 -> 139617236111616
	139617236113248 -> 139617235955584 [dir=none]
	139617235955584 [label="index
 (590)" fillcolor=orange]
	139617236113248 -> 139617235954688 [dir=none]
	139617235954688 [label="source
 (590, 128)" fillcolor=orange]
	139617236113248 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618570609376 -> 139617236113248
	139618570609376 [label=CloneBackward]
	139618570609568 -> 139618570609376
	139618570609568 -> 139617235953152 [dir=none]
	139617235953152 [label="result
 (68, 128)" fillcolor=orange]
	139618570609568 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618570610000 -> 139618570609568
	139618570610000 -> 139617236184256 [dir=none]
	139617236184256 [label="mat1
 (68, 128)" fillcolor=orange]
	139618570610000 -> 139617236184576 [dir=none]
	139617236184576 [label="mat2
 (128, 128)" fillcolor=orange]
	139618570610000 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618570610672 -> 139618570610000
	139617200673664 [label="model.actor2actor_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200673664 -> 139618570610672
	139618570610672 [label=AccumulateGrad]
	139618677206176 -> 139618570610000
	139618677206176 -> 139617199912576 [dir=none]
	139617199912576 [label="result
 (68, 128)" fillcolor=orange]
	139618677206176 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618570611440 -> 139618677206176
	139618570611440 [label="AddBackward0
------------
alpha: 1"]
	139618570612304 -> 139618570611440
	139618570612304 -> 139617200186176 [dir=none]
	139617200186176 [label="mat1
 (68, 128)" fillcolor=orange]
	139618570612304 -> 139617199912064 [dir=none]
	139617199912064 [label="mat2
 (128, 128)" fillcolor=orange]
	139618570612304 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618570612496 -> 139618570612304
	139617200672832 [label="model.actor2actor_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139617200672832 -> 139618570612496
	139618570612496 [label=AccumulateGrad]
	139618570612688 -> 139618570612304
	139618570612688 -> 139617199914368 [dir=none]
	139617199914368 [label="result
 (68, 128)" fillcolor=orange]
	139618570612688 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618570610432 -> 139618570612688
	139618570610432 -> 139617236184768 [dir=none]
	139617236184768 [label="bias
 (128)" fillcolor=orange]
	139618570610432 -> 139617236183168 [dir=none]
	139617236183168 [label="input
 (68, 128)" fillcolor=orange]
	139618570610432 -> 139617236181120 [dir=none]
	139617236181120 [label="result1
 (68, 1)" fillcolor=orange]
	139618570610432 -> 139618771980672 [dir=none]
	139618771980672 [label="result2
 (68, 1)" fillcolor=orange]
	139618570610432 -> 139618771982464 [dir=none]
	139618771982464 [label="weight
 (128)" fillcolor=orange]
	139618570610432 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617219695712 -> 139618570610432
	139617219695712 -> 139618771983296 [dir=none]
	139618771983296 [label="index
 (590)" fillcolor=orange]
	139617219695712 -> 139618771983744 [dir=none]
	139618771983744 [label="source
 (590, 128)" fillcolor=orange]
	139617219695712 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617219694992 -> 139617219695712
	139617219694992 [label=CloneBackward]
	139617219694800 -> 139617219694992
	139617219694800 -> 139618771980352 [dir=none]
	139618771980352 [label="result
 (68, 128)" fillcolor=orange]
	139617219694800 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617219697344 -> 139617219694800
	139617219697344 -> 139618771981504 [dir=none]
	139618771981504 [label="mat1
 (68, 128)" fillcolor=orange]
	139617219697344 -> 139618771984192 [dir=none]
	139618771984192 [label="mat2
 (128, 128)" fillcolor=orange]
	139617219697344 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617229448096 -> 139617219697344
	139617200801472 [label="model.actor2actor_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200801472 -> 139617229448096
	139617229448096 [label=AccumulateGrad]
	139618570611632 -> 139617219697344
	139618570611632 -> 139618771981952 [dir=none]
	139618771981952 [label="result
 (68, 128)" fillcolor=orange]
	139618570611632 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617229449152 -> 139618570611632
	139617229449152 [label="AddBackward0
------------
alpha: 1"]
	139617229449872 -> 139617229449152
	139617229449872 -> 139617232603264 [dir=none]
	139617232603264 [label="mat1
 (68, 128)" fillcolor=orange]
	139617229449872 -> 139617232602432 [dir=none]
	139617232602432 [label="mat2
 (128, 128)" fillcolor=orange]
	139617229449872 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617229450064 -> 139617229449872
	139617200800448 [label="model.actor2actor_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139617200800448 -> 139617229450064
	139617229450064 [label=AccumulateGrad]
	139617229450208 -> 139617229449872
	139617229450208 -> 139617231368896 [dir=none]
	139617231368896 [label="result
 (68, 128)" fillcolor=orange]
	139617229450208 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617229450304 -> 139617229450208
	139617229450304 -> 139617231371648 [dir=none]
	139617231371648 [label="bias
 (128)" fillcolor=orange]
	139617229450304 -> 139617231370368 [dir=none]
	139617231370368 [label="input
 (68, 128)" fillcolor=orange]
	139617229450304 -> 139617231369600 [dir=none]
	139617231369600 [label="result1
 (68, 1)" fillcolor=orange]
	139617229450304 -> 139617231369792 [dir=none]
	139617231369792 [label="result2
 (68, 1)" fillcolor=orange]
	139617229450304 -> 139617231372096 [dir=none]
	139617231372096 [label="weight
 (128)" fillcolor=orange]
	139617229450304 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617229451168 -> 139617229450304
	139617229451168 -> 139617231370752 [dir=none]
	139617231370752 [label="index
 (590)" fillcolor=orange]
	139617229451168 -> 139617231368832 [dir=none]
	139617231368832 [label="source
 (590, 128)" fillcolor=orange]
	139617229451168 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617229449392 -> 139617229451168
	139617229449392 [label=CloneBackward]
	139618562224768 -> 139617229449392
	139618562224768 -> 139617231372032 [dir=none]
	139617231372032 [label="result
 (68, 128)" fillcolor=orange]
	139618562224768 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562224960 -> 139618562224768
	139618562224960 -> 139617232601408 [dir=none]
	139617232601408 [label="mat1
 (68, 128)" fillcolor=orange]
	139618562224960 -> 139617232604800 [dir=none]
	139617232604800 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562224960 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562225248 -> 139618562224960
	139617201228288 [label="model.actor2actor_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201228288 -> 139618562225248
	139618562225248 [label=AccumulateGrad]
	139617229449248 -> 139618562224960
	139617229449248 -> 139617220054656 [dir=none]
	139617220054656 [label="result
 (68, 128)" fillcolor=orange]
	139617229449248 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562225056 -> 139617229449248
	139618562225056 [label="AddBackward0
------------
alpha: 1"]
	139618562225584 -> 139618562225056
	139618562225584 -> 139617220054144 [dir=none]
	139617220054144 [label="mat1
 (68, 128)" fillcolor=orange]
	139618562225584 -> 139617220054400 [dir=none]
	139617220054400 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562225584 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562226448 -> 139618562225584
	139617201226752 [label="model.lane2actor_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139617201226752 -> 139618562226448
	139618562226448 [label=AccumulateGrad]
	139618562226112 -> 139618562225584
	139618562226112 -> 139617232603584 [dir=none]
	139617232603584 [label="result
 (68, 128)" fillcolor=orange]
	139618562226112 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562226928 -> 139618562226112
	139618562226928 -> 139617232602880 [dir=none]
	139617232602880 [label="bias
 (128)" fillcolor=orange]
	139618562226928 -> 139617232604864 [dir=none]
	139617232604864 [label="input
 (68, 128)" fillcolor=orange]
	139618562226928 -> 139617232602624 [dir=none]
	139617232602624 [label="result1
 (68, 1)" fillcolor=orange]
	139618562226928 -> 139617230719552 [dir=none]
	139617230719552 [label="result2
 (68, 1)" fillcolor=orange]
	139618562226928 -> 139617230719360 [dir=none]
	139617230719360 [label="weight
 (128)" fillcolor=orange]
	139618562226928 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139618562225200 -> 139618562226928
	139618562225200 -> 139617220053504 [dir=none]
	139617220053504 [label="index
 (156865)" fillcolor=orange]
	139618562225200 -> 139617220053824 [dir=none]
	139617220053824 [label="source
 (156865, 128)" fillcolor=orange]
	139618562225200 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618562227744 -> 139618562225200
	139618562227744 [label=CloneBackward]
	139618562227936 -> 139618562227744
	139618562227936 -> 139617220052096 [dir=none]
	139617220052096 [label="result
 (68, 128)" fillcolor=orange]
	139618562227936 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562228128 -> 139618562227936
	139618562228128 -> 139617220051328 [dir=none]
	139617220051328 [label="mat1
 (68, 128)" fillcolor=orange]
	139618562228128 -> 139617230720256 [dir=none]
	139617230720256 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562228128 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562226016 -> 139618562228128
	139617201404736 [label="model.lane2actor_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201404736 -> 139618562226016
	139618562226016 [label=AccumulateGrad]
	139618562225824 -> 139618562228128
	139618562225824 -> 139618767117376 [dir=none]
	139618767117376 [label="result
 (68, 128)" fillcolor=orange]
	139618562225824 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562225728 -> 139618562225824
	139618562225728 [label="AddBackward0
------------
alpha: 1"]
	139618562226400 -> 139618562225728
	139618562226400 -> 139618767117696 [dir=none]
	139618767117696 [label="mat1
 (68, 128)" fillcolor=orange]
	139618562226400 -> 139618767116096 [dir=none]
	139618767116096 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562226400 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562224336 -> 139618562226400
	139617201403712 [label="model.lane2actor_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139617201403712 -> 139618562224336
	139618562224336 [label=AccumulateGrad]
	139618562224192 -> 139618562226400
	139618562224192 -> 139617230720512 [dir=none]
	139617230720512 [label="result
 (68, 128)" fillcolor=orange]
	139618562224192 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232630208 -> 139618562224192
	139617232630208 -> 139617230718656 [dir=none]
	139617230718656 [label="bias
 (128)" fillcolor=orange]
	139617232630208 -> 139617230720576 [dir=none]
	139617230720576 [label="input
 (68, 128)" fillcolor=orange]
	139617232630208 -> 139617230718976 [dir=none]
	139617230718976 [label="result1
 (68, 1)" fillcolor=orange]
	139617232630208 -> 139617235468032 [dir=none]
	139617235468032 [label="result2
 (68, 1)" fillcolor=orange]
	139617232630208 -> 139617235465792 [dir=none]
	139617235465792 [label="weight
 (128)" fillcolor=orange]
	139617232630208 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617232633088 -> 139617232630208
	139617232633088 -> 139617235466880 [dir=none]
	139617235466880 [label="index
 (156865)" fillcolor=orange]
	139617232633088 -> 139617235467264 [dir=none]
	139617235467264 [label="source
 (156865, 128)" fillcolor=orange]
	139617232633088 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617232632368 -> 139617232633088
	139617232632368 [label=CloneBackward]
	139617232632752 -> 139617232632368
	139617232632752 -> 139617235465728 [dir=none]
	139617235465728 [label="result
 (68, 128)" fillcolor=orange]
	139617232632752 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232633424 -> 139617232632752
	139617232633424 -> 139618767116352 [dir=none]
	139618767116352 [label="mat1
 (68, 128)" fillcolor=orange]
	139617232633424 -> 139618767116736 [dir=none]
	139618767116736 [label="mat2
 (128, 128)" fillcolor=orange]
	139617232633424 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617232633808 -> 139617232633424
	139617217826432 [label="model.lane2actor_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217826432 -> 139617232633808
	139617232633808 [label=AccumulateGrad]
	139618562226640 -> 139617232633424
	139618562226640 -> 139617236168640 [dir=none]
	139617236168640 [label="result
 (68, 128)" fillcolor=orange]
	139618562226640 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232629920 -> 139618562226640
	139617232629920 [label="AddBackward0
------------
alpha: 1"]
	139617232630448 -> 139617232629920
	139617232630448 -> 139617228428416 [dir=none]
	139617228428416 [label="mat1
 (68, 128)" fillcolor=orange]
	139617232630448 -> 139617228428800 [dir=none]
	139617228428800 [label="mat2
 (128, 128)" fillcolor=orange]
	139617232630448 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617232630640 -> 139617232630448
	139617217825408 [label="model.lane2actor_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139617217825408 -> 139617232630640
	139617232630640 [label=AccumulateGrad]
	139617232630736 -> 139617232630448
	139617232630736 -> 139617215477504 [dir=none]
	139617215477504 [label="result
 (68, 128)" fillcolor=orange]
	139617232630736 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232630928 -> 139617232630736
	139617232630928 -> 139618767117568 [dir=none]
	139618767117568 [label="bias
 (128)" fillcolor=orange]
	139617232630928 -> 139617215477120 [dir=none]
	139617215477120 [label="input
 (68, 128)" fillcolor=orange]
	139617232630928 -> 139617215477248 [dir=none]
	139617215477248 [label="result1
 (68, 1)" fillcolor=orange]
	139617232630928 -> 139618767116480 [dir=none]
	139618767116480 [label="result2
 (68, 1)" fillcolor=orange]
	139617232630928 -> 139618767117952 [dir=none]
	139618767117952 [label="weight
 (128)" fillcolor=orange]
	139617232630928 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617232631648 -> 139617232630928
	139617232631648 -> 139618767117248 [dir=none]
	139618767117248 [label="index
 (156865)" fillcolor=orange]
	139617232631648 -> 139617228429952 [dir=none]
	139617228429952 [label="source
 (156865, 128)" fillcolor=orange]
	139617232631648 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617232632560 -> 139617232631648
	139617232632560 [label=CloneBackward]
	139617232633568 -> 139617232632560
	139617232633568 -> 139617228428288 [dir=none]
	139617228428288 [label="result
 (68, 128)" fillcolor=orange]
	139617232633568 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232629824 -> 139617232633568
	139617232629824 -> 139617228428672 [dir=none]
	139617228428672 [label="mat1
 (68, 128)" fillcolor=orange]
	139617232629824 -> 139617228430080 [dir=none]
	139617228430080 [label="mat2
 (128, 128)" fillcolor=orange]
	139617232629824 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617232633136 -> 139617232629824
	139617217823232 [label="model.lane2actor_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217823232 -> 139617232633136
	139617232633136 [label=AccumulateGrad]
	139617232630064 -> 139617232629824
	139617232630064 -> 139617228430336 [dir=none]
	139617228430336 [label="result
 (68, 128)" fillcolor=orange]
	139617232630064 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617229478400 -> 139617232630064
	139617229478400 [label="AddBackward0
------------
alpha: 1"]
	139617229479360 -> 139617229478400
	139617229479360 -> 139617228430144 [dir=none]
	139617228430144 [label="mat1
 (68, 128)" fillcolor=orange]
	139617229479360 -> 139617228428608 [dir=none]
	139617228428608 [label="mat2
 (128, 128)" fillcolor=orange]
	139617229479360 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618568973568 -> 139617229479360
	139617217469888 [label="model.lane2actor_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139617217469888 -> 139618568973568
	139618568973568 [label=AccumulateGrad]
	139618568970352 -> 139617229479360
	139618568970352 -> 139617228429312 [dir=none]
	139617228429312 [label="result
 (68, 128)" fillcolor=orange]
	139618568970352 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618568970880 -> 139618568970352
	139618568970880 -> 139617228431104 [dir=none]
	139617228431104 [label="bias
 (128)" fillcolor=orange]
	139618568970880 -> 139617228428928 [dir=none]
	139617228428928 [label="input
 (68, 128)" fillcolor=orange]
	139618568970880 -> 139617235959040 [dir=none]
	139617235959040 [label="result1
 (68, 1)" fillcolor=orange]
	139618568970880 -> 139617235956672 [dir=none]
	139617235956672 [label="result2
 (68, 1)" fillcolor=orange]
	139618568970880 -> 139617235959424 [dir=none]
	139617235959424 [label="weight
 (128)" fillcolor=orange]
	139618568970880 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139618568971984 -> 139618568970880
	139618568971984 -> 139617235959680 [dir=none]
	139617235959680 [label="index
 (156865)" fillcolor=orange]
	139618568971984 -> 139617235956352 [dir=none]
	139617235956352 [label="source
 (156865, 128)" fillcolor=orange]
	139618568971984 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618568972992 -> 139618568971984
	139618568972992 [label=CloneBackward]
	139618568973184 -> 139618568972992
	139618568973184 -> 139617235959488 [dir=none]
	139617235959488 [label="result
 (68, 128)" fillcolor=orange]
	139618568973184 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564223760 -> 139618568973184
	139618564223760 -> 139617235959360 [dir=none]
	139617235959360 [label="mat1
 (68, 128)" fillcolor=orange]
	139618564223760 -> 139617235958528 [dir=none]
	139617235958528 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564223760 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564223424 -> 139618564223760
	139617217467712 [label="model.lane2actor_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217467712 -> 139618564223424
	139618564223424 [label=AccumulateGrad]
	139618568972032 -> 139618564223760
	139618568972032 [label="CatBackward
-----------
dim: 0"]
	139618564223280 -> 139618568972032
	139618564223280 -> 139617235958080 [dir=none]
	139617235958080 [label="input
 (1, 128)" fillcolor=orange]
	139618564223280 -> 139617235957504 [dir=none]
	139617235957504 [label="result1
 (1, 1)" fillcolor=orange]
	139618564223280 -> 139617235958208 [dir=none]
	139617235958208 [label="result2
 (1, 1)" fillcolor=orange]
	139618564223280 -> 139617235958400 [dir=none]
	139617235958400 [label="weight
 (128)" fillcolor=orange]
	139618564223280 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :              1
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618564223376 -> 139618564223280
	139618564223376 -> 139617199970112 [dir=none]
	139617199970112 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564223376 -> 139617199968448 [dir=none]
	139617199968448 [label="self
 (1, 128)" fillcolor=orange]
	139618564223376 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :       (1, 128)
self_strides:       (128, 1)"]
	139618564223664 -> 139618564223376
	139618564223664 -> 139617235959232 [dir=none]
	139617235959232 [label="result
 (1, 128)" fillcolor=orange]
	139618564223664 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564223904 -> 139618564223664
	139618564223904 -> 139617235957696 [dir=none]
	139617235957696 [label="mat1
 (1, 128)" fillcolor=orange]
	139618564223904 -> 139617235958848 [dir=none]
	139617235958848 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564223904 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564224048 -> 139618564223904
	139617215929856 [label="model.ego_feature_extractor.2.bias
 (128)" fillcolor=lightblue]
	139617215929856 -> 139618564224048
	139618564224048 [label=AccumulateGrad]
	139618564223952 -> 139618564223904
	139618564223952 -> 139617215574784 [dir=none]
	139617215574784 [label="result
 (1, 128)" fillcolor=orange]
	139618564223952 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564224144 -> 139618564223952
	139618564224144 -> 139617215577792 [dir=none]
	139617215577792 [label="mat1
 (1, 15)" fillcolor=orange]
	139618564224144 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :        (1, 15)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :      (15, 128)
mat2_strides:        (1, 15)"]
	139618564224480 -> 139618564224144
	139617215929408 [label="model.ego_feature_extractor.0.bias
 (128)" fillcolor=lightblue]
	139617215929408 -> 139618564224480
	139618564224480 [label=AccumulateGrad]
	139618564224432 -> 139618564224144
	139618564224432 [label=TBackward]
	139618564224528 -> 139618564224432
	139617215929600 [label="model.ego_feature_extractor.0.weight
 (128, 15)" fillcolor=lightblue]
	139617215929600 -> 139618564224528
	139618564224528 [label=AccumulateGrad]
	139618564223712 -> 139618564223904
	139618564223712 [label=TBackward]
	139618564224624 -> 139618564223712
	139617215929664 [label="model.ego_feature_extractor.2.weight
 (128, 128)" fillcolor=lightblue]
	139617215929664 -> 139618564224624
	139618564224624 [label=AccumulateGrad]
	139618564223568 -> 139618564223376
	139618564223568 [label=TBackward]
	139618564224336 -> 139618564223568
	139617215930304 [label="model.ego_feature_extractor.4.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617215930304 -> 139618564224336
	139618564224336 [label=AccumulateGrad]
	139618564223328 -> 139618564223280
	139617216286784 [label="model.ego_feature_extractor.4.norm.weight
 (128)" fillcolor=lightblue]
	139617216286784 -> 139618564223328
	139618564223328 [label=AccumulateGrad]
	139618564225920 -> 139618564223280
	139617216287040 [label="model.ego_feature_extractor.4.norm.bias
 (128)" fillcolor=lightblue]
	139617216287040 -> 139618564225920
	139618564225920 [label=AccumulateGrad]
	139618564223184 -> 139618568972032
	139618564223184 -> 139617235956864 [dir=none]
	139617235956864 [label="input
 (67, 128)" fillcolor=orange]
	139618564223184 -> 139617235956544 [dir=none]
	139617235956544 [label="result1
 (67, 1)" fillcolor=orange]
	139618564223184 -> 139617235956480 [dir=none]
	139617235956480 [label="result2
 (67, 1)" fillcolor=orange]
	139618564223184 -> 139617235958592 [dir=none]
	139617235958592 [label="weight
 (128)" fillcolor=orange]
	139618564223184 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :             67
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618564224096 -> 139618564223184
	139618564224096 -> 139617235957568 [dir=none]
	139617235957568 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564224096 -> 139617199971648 [dir=none]
	139617199971648 [label="self
 (67, 128)" fillcolor=orange]
	139618564224096 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :      (67, 128)
self_strides:       (128, 1)"]
	139618564224192 -> 139618564224096
	139618564224192 -> 139617235957440 [dir=none]
	139617235957440 [label="self
 (67, 128)" fillcolor=orange]
	139618564224192 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139618564224912 -> 139618564224192
	139618564224912 -> 139617215577280 [dir=none]
	139617215577280 [label="mat1
 (67, 128)" fillcolor=orange]
	139618564224912 -> 139617215576512 [dir=none]
	139617215576512 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564224912 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (67, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564225056 -> 139618564224912
	139617216288000 [label="model.agent_feature_extractor.2.bias
 (128)" fillcolor=lightblue]
	139617216288000 -> 139618564225056
	139618564225056 [label=AccumulateGrad]
	139618564225008 -> 139618564224912
	139618564225008 -> 139617199971136 [dir=none]
	139617199971136 [label="result
 (67, 128)" fillcolor=orange]
	139618564225008 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564225200 -> 139618564225008
	139618564225200 -> 139617199971904 [dir=none]
	139617199971904 [label="mat1
 (67, 40)" fillcolor=orange]
	139618564225200 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (67, 40)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :      (40, 128)
mat2_strides:        (1, 40)"]
	139618564225488 -> 139618564225200
	139617216287424 [label="model.agent_feature_extractor.0.bias
 (128)" fillcolor=lightblue]
	139617216287424 -> 139618564225488
	139618564225488 [label=AccumulateGrad]
	139618564225392 -> 139618564225200
	139618564225392 [label=TBackward]
	139618564225584 -> 139618564225392
	139617216287680 [label="model.agent_feature_extractor.0.weight
 (128, 40)" fillcolor=lightblue]
	139617216287680 -> 139618564225584
	139618564225584 [label=AccumulateGrad]
	139618564224672 -> 139618564224912
	139618564224672 [label=TBackward]
	139618564225632 -> 139618564224672
	139617216287808 [label="model.agent_feature_extractor.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216287808 -> 139618564225632
	139618564225632 [label=AccumulateGrad]
	139618564223856 -> 139618564224096
	139618564223856 [label=TBackward]
	139618564225296 -> 139618564223856
	139617216288448 [label="model.agent_feature_extractor.4.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617216288448 -> 139618564225296
	139618564225296 [label=AccumulateGrad]
	139618564223520 -> 139618564223184
	139617216288512 [label="model.agent_feature_extractor.4.norm.weight
 (128)" fillcolor=lightblue]
	139617216288512 -> 139618564223520
	139618564223520 [label=AccumulateGrad]
	139618564223472 -> 139618564223184
	139617216288768 [label="model.agent_feature_extractor.4.norm.bias
 (128)" fillcolor=lightblue]
	139617216288768 -> 139618564223472
	139618564223472 [label=AccumulateGrad]
	139618564224288 -> 139618564223760
	139618564224288 [label=TBackward]
	139618564224768 -> 139618564224288
	139617217467648 [label="model.lane2actor_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217467648 -> 139618564224768
	139618564224768 [label=AccumulateGrad]
	139618568972464 -> 139618568971984
	139618568972464 -> 139617199971392 [dir=none]
	139617199971392 [label="mat1
 (156865, 128)" fillcolor=orange]
	139618568972464 -> 139617230160384 [dir=none]
	139617230160384 [label="mat2
 (128, 128)" fillcolor=orange]
	139618568972464 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564223808 -> 139618568972464
	139617217469184 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617217469184 -> 139618564223808
	139618564223808 [label=AccumulateGrad]
	139618564224240 -> 139618568972464
	139618564224240 -> 139617230162880 [dir=none]
	139617230162880 [label="result
 (156865, 128)" fillcolor=orange]
	139618564224240 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564225824 -> 139618564224240
	139618564225824 -> 139617230160768 [dir=none]
	139617230160768 [label="mat1
 (156865, 384)" fillcolor=orange]
	139618564225824 -> 139617230163136 [dir=none]
	139617230163136 [label="mat2
 (384, 128)" fillcolor=orange]
	139618564225824 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618564224864 -> 139618564225824
	139617217468864 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217468864 -> 139618564224864
	139618564224864 [label=AccumulateGrad]
	139618564225776 -> 139618564225824
	139618564225776 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139618564226016 -> 139618564225776
	139618564226016 -> 139617230161792 [dir=none]
	139617230161792 [label="indices[0]
 (156865)" fillcolor=orange]
	139618564226016 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618564226400 -> 139618564226016
	139618564226400 -> 139617230162752 [dir=none]
	139617230162752 [label="result
 (9921, 128)" fillcolor=orange]
	139618564226400 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564226496 -> 139618564226400
	139618564226496 -> 139617230162560 [dir=none]
	139617230162560 [label="mat1
 (9921, 128)" fillcolor=orange]
	139618564226496 -> 139617230163648 [dir=none]
	139617230163648 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564226496 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564226592 -> 139618564226496
	139617217467072 [label="model.lane2actor_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217467072 -> 139618564226592
	139618564226592 [label=AccumulateGrad]
	139618564226544 -> 139618564226496
	139618564226544 -> 139617230159936 [dir=none]
	139617230159936 [label="result
 (9921, 128)" fillcolor=orange]
	139618564226544 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564226736 -> 139618564226544
	139618564226736 [label="AddBackward0
------------
alpha: 1"]
	139618564226976 -> 139618564226736
	139618564226976 -> 139617230163840 [dir=none]
	139617230163840 [label="mat1
 (9921, 128)" fillcolor=orange]
	139618564226976 -> 139617230163520 [dir=none]
	139617230163520 [label="mat2
 (128, 128)" fillcolor=orange]
	139618564226976 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618564224384 -> 139618564226976
	139617217466432 [label="model.actor2lane_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139617217466432 -> 139618564224384
	139618564224384 [label=AccumulateGrad]
	139618564223232 -> 139618564226976
	139618564223232 -> 139617230160960 [dir=none]
	139617230160960 [label="result
 (9921, 128)" fillcolor=orange]
	139618564223232 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618564225344 -> 139618564223232
	139618564225344 -> 139617230163456 [dir=none]
	139617230163456 [label="bias
 (128)" fillcolor=orange]
	139618564225344 -> 139617230160320 [dir=none]
	139617230160320 [label="input
 (9921, 128)" fillcolor=orange]
	139618564225344 -> 139617230161856 [dir=none]
	139617230161856 [label="result1
 (9921, 1)" fillcolor=orange]
	139618564225344 -> 139617230161984 [dir=none]
	139617230161984 [label="result2
 (9921, 1)" fillcolor=orange]
	139618564225344 -> 139617230160448 [dir=none]
	139617230160448 [label="weight
 (128)" fillcolor=orange]
	139618564225344 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617219466048 -> 139618564225344
	139617219466048 -> 139617230163776 [dir=none]
	139617230163776 [label="index
 (156865)" fillcolor=orange]
	139617219466048 -> 139617230160192 [dir=none]
	139617230160192 [label="source
 (156865, 128)" fillcolor=orange]
	139617219466048 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617219257104 -> 139617219466048
	139617219257104 [label=CloneBackward]
	139617219257440 -> 139617219257104
	139617219257440 -> 139617230162432 [dir=none]
	139617230162432 [label="result
 (9921, 128)" fillcolor=orange]
	139617219257440 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617219257728 -> 139617219257440
	139617219257728 -> 139617230163904 [dir=none]
	139617230163904 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617219257728 -> 139617230163328 [dir=none]
	139617230163328 [label="mat2
 (128, 128)" fillcolor=orange]
	139617219257728 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617219256576 -> 139617219257728
	139617217619648 [label="model.actor2lane_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217619648 -> 139617219256576
	139617219256576 [label=AccumulateGrad]
	139618564226928 -> 139617219257728
	139618564226928 -> 139617230163200 [dir=none]
	139617230163200 [label="result
 (9921, 128)" fillcolor=orange]
	139618564226928 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236082800 -> 139618564226928
	139617236082800 [label="AddBackward0
------------
alpha: 1"]
	139617236082992 -> 139617236082800
	139617236082992 -> 139617230161728 [dir=none]
	139617230161728 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236082992 -> 139617230161088 [dir=none]
	139617230161088 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236082992 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236083184 -> 139617236082992
	139617217618624 [label="model.actor2lane_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139617217618624 -> 139617236083184
	139617236083184 [label=AccumulateGrad]
	139617236083088 -> 139617236082992
	139617236083088 -> 139617230162304 [dir=none]
	139617230162304 [label="result
 (9921, 128)" fillcolor=orange]
	139617236083088 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236083280 -> 139617236083088
	139617236083280 -> 139617230162624 [dir=none]
	139617230162624 [label="bias
 (128)" fillcolor=orange]
	139617236083280 -> 139617230160576 [dir=none]
	139617230160576 [label="input
 (9921, 128)" fillcolor=orange]
	139617236083280 -> 139617230161408 [dir=none]
	139617230161408 [label="result1
 (9921, 1)" fillcolor=orange]
	139617236083280 -> 139617230161536 [dir=none]
	139617230161536 [label="result2
 (9921, 1)" fillcolor=orange]
	139617236083280 -> 139617230160000 [dir=none]
	139617230160000 [label="weight
 (128)" fillcolor=orange]
	139617236083280 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617236083568 -> 139617236083280
	139617236083568 -> 139617230161024 [dir=none]
	139617230161024 [label="index
 (156865)" fillcolor=orange]
	139617236083568 -> 139617230161216 [dir=none]
	139617230161216 [label="source
 (156865, 128)" fillcolor=orange]
	139617236083568 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617236083760 -> 139617236083568
	139617236083760 [label=CloneBackward]
	139617236083904 -> 139617236083760
	139617236083904 -> 139617230161664 [dir=none]
	139617230161664 [label="result
 (9921, 128)" fillcolor=orange]
	139617236083904 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236084048 -> 139617236083904
	139617236084048 -> 139617230163392 [dir=none]
	139617230163392 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236084048 -> 139617230162368 [dir=none]
	139617230162368 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236084048 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236084144 -> 139617236084048
	139617216752128 [label="model.actor2lane_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216752128 -> 139617236084144
	139617236084144 [label=AccumulateGrad]
	139617236082944 -> 139617236084048
	139617236082944 -> 139617220313792 [dir=none]
	139617220313792 [label="result
 (9921, 128)" fillcolor=orange]
	139617236082944 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236084192 -> 139617236082944
	139617236084192 [label="AddBackward0
------------
alpha: 1"]
	139617236084384 -> 139617236084192
	139617236084384 -> 139617220313600 [dir=none]
	139617220313600 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236084384 -> 139617220316480 [dir=none]
	139617220316480 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236084384 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236084528 -> 139617236084384
	139617216751104 [label="model.actor2lane_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139617216751104 -> 139617236084528
	139617236084528 [label=AccumulateGrad]
	139617236084480 -> 139617236084384
	139617236084480 -> 139617220316992 [dir=none]
	139617220316992 [label="result
 (9921, 128)" fillcolor=orange]
	139617236084480 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236084624 -> 139617236084480
	139617236084624 -> 139617220314240 [dir=none]
	139617220314240 [label="bias
 (128)" fillcolor=orange]
	139617236084624 -> 139617220315584 [dir=none]
	139617220315584 [label="input
 (9921, 128)" fillcolor=orange]
	139617236084624 -> 139617220316288 [dir=none]
	139617220316288 [label="result1
 (9921, 1)" fillcolor=orange]
	139617236084624 -> 139617220316736 [dir=none]
	139617220316736 [label="result2
 (9921, 1)" fillcolor=orange]
	139617236084624 -> 139617220315264 [dir=none]
	139617220315264 [label="weight
 (128)" fillcolor=orange]
	139617236084624 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617236084912 -> 139617236084624
	139617236084912 -> 139617220315072 [dir=none]
	139617220315072 [label="index
 (156865)" fillcolor=orange]
	139617236084912 -> 139617220313280 [dir=none]
	139617220313280 [label="source
 (156865, 128)" fillcolor=orange]
	139617236084912 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617236085296 -> 139617236084912
	139617236085296 [label=CloneBackward]
	139617236085536 -> 139617236085296
	139617236085536 -> 139617220313536 [dir=none]
	139617220313536 [label="result
 (9921, 128)" fillcolor=orange]
	139617236085536 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236085680 -> 139617236085536
	139617236085680 -> 139617220315328 [dir=none]
	139617220315328 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236085680 -> 139617220313344 [dir=none]
	139617220313344 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236085680 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236085824 -> 139617236085680
	139617216912704 [label="model.actor2lane_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216912704 -> 139617236085824
	139617236085824 [label=AccumulateGrad]
	139617236084336 -> 139617236085680
	139617236084336 -> 139617220316800 [dir=none]
	139617220316800 [label="result
 (9921, 128)" fillcolor=orange]
	139617236084336 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236085872 -> 139617236084336
	139617236085872 [label="AddBackward0
------------
alpha: 1"]
	139617236086064 -> 139617236085872
	139617236086064 -> 139617220315200 [dir=none]
	139617220315200 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236086064 -> 139617220313152 [dir=none]
	139617220313152 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236086064 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236086304 -> 139617236086064
	139617216911680 [label="model.actor2lane_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139617216911680 -> 139617236086304
	139617236086304 [label=AccumulateGrad]
	139617236086256 -> 139617236086064
	139617236086256 -> 139617220315712 [dir=none]
	139617220315712 [label="result
 (9921, 128)" fillcolor=orange]
	139617236086256 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236086400 -> 139617236086256
	139617236086400 -> 139617220316352 [dir=none]
	139617220316352 [label="bias
 (128)" fillcolor=orange]
	139617236086400 -> 139617220316672 [dir=none]
	139617220316672 [label="input
 (9921, 128)" fillcolor=orange]
	139617236086400 -> 139617220317120 [dir=none]
	139617220317120 [label="result1
 (9921, 1)" fillcolor=orange]
	139617236086400 -> 139617220313664 [dir=none]
	139617220313664 [label="result2
 (9921, 1)" fillcolor=orange]
	139617236086400 -> 139617220317056 [dir=none]
	139617220317056 [label="weight
 (128)" fillcolor=orange]
	139617236086400 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139617236086592 -> 139617236086400
	139617236086592 -> 139617220314048 [dir=none]
	139617220314048 [label="index
 (156865)" fillcolor=orange]
	139617236086592 -> 139617220315136 [dir=none]
	139617220315136 [label="source
 (156865, 128)" fillcolor=orange]
	139617236086592 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617236082752 -> 139617236086592
	139617236082752 [label=CloneBackward]
	139617236083520 -> 139617236082752
	139617236083520 -> 139617220314368 [dir=none]
	139617220314368 [label="result
 (9921, 128)" fillcolor=orange]
	139617236083520 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236084672 -> 139617236083520
	139617236084672 -> 139617231696576 [dir=none]
	139617231696576 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617236084672 -> 139617231698560 [dir=none]
	139617231698560 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236084672 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236085056 -> 139617236084672
	139617216909504 [label="model.actor2lane_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216909504 -> 139617236085056
	139617236085056 [label=AccumulateGrad]
	139617236086016 -> 139617236084672
	139617236086016 -> 139617231697536 [dir=none]
	139617231697536 [label="input
 (9921, 128)" fillcolor=orange]
	139617236086016 -> 139617231697600 [dir=none]
	139617231697600 [label="result1
 (9921, 1)" fillcolor=orange]
	139617236086016 -> 139617231699328 [dir=none]
	139617231699328 [label="result2
 (9921, 1)" fillcolor=orange]
	139617236086016 -> 139617231696000 [dir=none]
	139617231696000 [label="weight
 (128)" fillcolor=orange]
	139617236086016 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139617236085392 -> 139617236086016
	139617236085392 -> 139617231697472 [dir=none]
	139617231697472 [label="mat2
 (134, 128)" fillcolor=orange]
	139617236085392 -> 139617231699712 [dir=none]
	139617231699712 [label="self
 (9921, 134)" fillcolor=orange]
	139617236085392 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (134, 128)
mat2_strides:       (1, 134)
self        : [saved tensor]
self_sizes  :    (9921, 134)
self_strides:       (134, 1)"]
	139617236086208 -> 139617236085392
	139617236086208 [label="CatBackward
-----------
dim: 1"]
	139618771067136 -> 139617236086208
	139618771067136 -> 139617231697344 [dir=none]
	139617231697344 [label="result
 (9921, 128)" fillcolor=orange]
	139618771067136 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618771067280 -> 139618771067136
	139618771067280 [label="AddBackward0
------------
alpha: 1"]
	139618771067376 -> 139618771067280
	139618771067376 -> 139617231699200 [dir=none]
	139617231699200 [label="input
 (9921, 128)" fillcolor=orange]
	139618771067376 -> 139617231696448 [dir=none]
	139617231696448 [label="result1
 (9921, 1)" fillcolor=orange]
	139618771067376 -> 139617231696064 [dir=none]
	139617231696064 [label="result2
 (9921, 1)" fillcolor=orange]
	139618771067376 -> 139617231698048 [dir=none]
	139617231698048 [label="weight
 (128)" fillcolor=orange]
	139618771067376 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618771067616 -> 139618771067376
	139618771067616 -> 139617231698880 [dir=none]
	139617231698880 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771067616 -> 139617231696320 [dir=none]
	139617231696320 [label="self
 (9921, 128)" fillcolor=orange]
	139618771067616 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618771067904 -> 139618771067616
	139618771067904 -> 139617231697856 [dir=none]
	139617231697856 [label="result
 (9921, 128)" fillcolor=orange]
	139618771067904 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618771068144 -> 139618771067904
	139618771068144 -> 139617231699072 [dir=none]
	139617231699072 [label="input
 (9921, 128)" fillcolor=orange]
	139618771068144 -> 139617231699136 [dir=none]
	139617231699136 [label="result1
 (9921, 1)" fillcolor=orange]
	139618771068144 -> 139617231699776 [dir=none]
	139617231699776 [label="result2
 (9921, 1)" fillcolor=orange]
	139618771068144 -> 139617231698688 [dir=none]
	139617231698688 [label="weight
 (128)" fillcolor=orange]
	139618771068144 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618771068240 -> 139618771068144
	139618771068240 -> 139617231697216 [dir=none]
	139617231697216 [label="index
 (9873)" fillcolor=orange]
	139618771068240 -> 139617231698432 [dir=none]
	139617231698432 [label="source
 (9873, 128)" fillcolor=orange]
	139618771068240 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771068624 -> 139618771068240
	139618771068624 -> 139617231699840 [dir=none]
	139617231699840 [label="index
 (9873)" fillcolor=orange]
	139618771068624 -> 139617231696384 [dir=none]
	139617231696384 [label="source
 (9873, 128)" fillcolor=orange]
	139618771068624 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771067664 -> 139618771068624
	139618771067664 -> 139617231699520 [dir=none]
	139617231699520 [label="index
 (9885)" fillcolor=orange]
	139618771067664 -> 139617231699648 [dir=none]
	139617231699648 [label="source
 (9885, 128)" fillcolor=orange]
	139618771067664 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771068384 -> 139618771067664
	139618771068384 -> 139617231699904 [dir=none]
	139617231699904 [label="index
 (9885)" fillcolor=orange]
	139618771068384 -> 139617231697792 [dir=none]
	139617231697792 [label="source
 (9885, 128)" fillcolor=orange]
	139618771068384 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771068720 -> 139618771068384
	139618771068720 -> 139617231697408 [dir=none]
	139617231697408 [label="index
 (9897)" fillcolor=orange]
	139618771068720 -> 139617230091264 [dir=none]
	139617230091264 [label="source
 (9897, 128)" fillcolor=orange]
	139618771068720 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771068912 -> 139618771068720
	139618771068912 -> 139617230091392 [dir=none]
	139617230091392 [label="index
 (9897)" fillcolor=orange]
	139618771068912 -> 139617230093440 [dir=none]
	139617230093440 [label="source
 (9897, 128)" fillcolor=orange]
	139618771068912 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771069152 -> 139618771068912
	139618771069152 -> 139617230092160 [dir=none]
	139617230092160 [label="index
 (9909)" fillcolor=orange]
	139618771069152 -> 139617230091520 [dir=none]
	139617230091520 [label="source
 (9909, 128)" fillcolor=orange]
	139618771069152 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771069296 -> 139618771069152
	139618771069296 -> 139617230093696 [dir=none]
	139617230093696 [label="index
 (9909)" fillcolor=orange]
	139618771069296 -> 139617230091072 [dir=none]
	139617230091072 [label="source
 (9909, 128)" fillcolor=orange]
	139618771069296 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771069440 -> 139618771069296
	139618771069440 -> 139617230091712 [dir=none]
	139617230091712 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771069440 -> 139617230092608 [dir=none]
	139617230092608 [label="self
 (9921, 128)" fillcolor=orange]
	139618771069440 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618771067328 -> 139618771069440
	139618771067328 -> 139617230091200 [dir=none]
	139617230091200 [label="result
 (9921, 128)" fillcolor=orange]
	139618771067328 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618771069728 -> 139618771067328
	139618771069728 [label="AddBackward0
------------
alpha: 1"]
	139618771069872 -> 139618771069728
	139618771069872 -> 139617230092416 [dir=none]
	139617230092416 [label="input
 (9921, 128)" fillcolor=orange]
	139618771069872 -> 139617230092480 [dir=none]
	139617230092480 [label="result1
 (9921, 1)" fillcolor=orange]
	139618771069872 -> 139617230090304 [dir=none]
	139617230090304 [label="result2
 (9921, 1)" fillcolor=orange]
	139618771069872 -> 139617230092096 [dir=none]
	139617230092096 [label="weight
 (128)" fillcolor=orange]
	139618771069872 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618771070160 -> 139618771069872
	139618771070160 -> 139617260808320 [dir=none]
	139617260808320 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771070160 -> 139617273388352 [dir=none]
	139617273388352 [label="self
 (9921, 128)" fillcolor=orange]
	139618771070160 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618771070496 -> 139618771070160
	139618771070496 -> 139617230091008 [dir=none]
	139617230091008 [label="result
 (9921, 128)" fillcolor=orange]
	139618771070496 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618771070688 -> 139618771070496
	139618771070688 -> 139617230093824 [dir=none]
	139617230093824 [label="input
 (9921, 128)" fillcolor=orange]
	139618771070688 -> 139617230094272 [dir=none]
	139617230094272 [label="result1
 (9921, 1)" fillcolor=orange]
	139618771070688 -> 139617230092224 [dir=none]
	139617230092224 [label="result2
 (9921, 1)" fillcolor=orange]
	139618771070688 -> 139617230093952 [dir=none]
	139617230093952 [label="weight
 (128)" fillcolor=orange]
	139618771070688 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618771070880 -> 139618771070688
	139618771070880 -> 139617230092352 [dir=none]
	139617230092352 [label="index
 (9873)" fillcolor=orange]
	139618771070880 -> 139617230093376 [dir=none]
	139617230093376 [label="source
 (9873, 128)" fillcolor=orange]
	139618771070880 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771068672 -> 139618771070880
	139618771068672 -> 139617230094208 [dir=none]
	139617230094208 [label="index
 (9873)" fillcolor=orange]
	139618771068672 -> 139617230091136 [dir=none]
	139617230091136 [label="source
 (9873, 128)" fillcolor=orange]
	139618771068672 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771069104 -> 139618771068672
	139618771069104 -> 139617230094144 [dir=none]
	139617230094144 [label="index
 (9885)" fillcolor=orange]
	139618771069104 -> 139617230093248 [dir=none]
	139617230093248 [label="source
 (9885, 128)" fillcolor=orange]
	139618771069104 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771070016 -> 139618771069104
	139618771070016 -> 139617230094016 [dir=none]
	139617230094016 [label="index
 (9885)" fillcolor=orange]
	139618771070016 -> 139617236280128 [dir=none]
	139617236280128 [label="source
 (9885, 128)" fillcolor=orange]
	139618771070016 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771070208 -> 139618771070016
	139618771070208 -> 139617236280256 [dir=none]
	139617236280256 [label="index
 (9897)" fillcolor=orange]
	139618771070208 -> 139617236279808 [dir=none]
	139617236279808 [label="source
 (9897, 128)" fillcolor=orange]
	139618771070208 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618771070592 -> 139618771070208
	139618771070592 -> 139617236280320 [dir=none]
	139617236280320 [label="index
 (9897)" fillcolor=orange]
	139618771070592 -> 139617236282112 [dir=none]
	139617236282112 [label="source
 (9897, 128)" fillcolor=orange]
	139618771070592 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139617237341856 -> 139618771070592
	139617237341856 -> 139617236280384 [dir=none]
	139617236280384 [label="index
 (9909)" fillcolor=orange]
	139617237341856 -> 139617236281792 [dir=none]
	139617236281792 [label="source
 (9909, 128)" fillcolor=orange]
	139617237341856 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769084576 -> 139617237341856
	139618769084576 -> 139617236282368 [dir=none]
	139617236282368 [label="index
 (9909)" fillcolor=orange]
	139618769084576 -> 139617236283136 [dir=none]
	139617236283136 [label="source
 (9909, 128)" fillcolor=orange]
	139618769084576 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769084816 -> 139618769084576
	139618769084816 -> 139617236281856 [dir=none]
	139617236281856 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769084816 -> 139617236282944 [dir=none]
	139617236282944 [label="self
 (9921, 128)" fillcolor=orange]
	139618769084816 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618771069776 -> 139618769084816
	139618771069776 -> 139617236279680 [dir=none]
	139617236279680 [label="result
 (9921, 128)" fillcolor=orange]
	139618771069776 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618769085392 -> 139618771069776
	139618769085392 [label="AddBackward0
------------
alpha: 1"]
	139618769085536 -> 139618769085392
	139618769085536 -> 139617236281728 [dir=none]
	139617236281728 [label="input
 (9921, 128)" fillcolor=orange]
	139618769085536 -> 139617236280960 [dir=none]
	139617236280960 [label="result1
 (9921, 1)" fillcolor=orange]
	139618769085536 -> 139617236282432 [dir=none]
	139617236282432 [label="result2
 (9921, 1)" fillcolor=orange]
	139618769085536 -> 139617236280704 [dir=none]
	139617236280704 [label="weight
 (128)" fillcolor=orange]
	139618769085536 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618769085968 -> 139618769085536
	139618769085968 -> 139617236281408 [dir=none]
	139617236281408 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769085968 -> 139617231490880 [dir=none]
	139617231490880 [label="self
 (9921, 128)" fillcolor=orange]
	139618769085968 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618769086304 -> 139618769085968
	139618769086304 -> 139617236282816 [dir=none]
	139617236282816 [label="result
 (9921, 128)" fillcolor=orange]
	139618769086304 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618769086544 -> 139618769086304
	139618769086544 -> 139617236282496 [dir=none]
	139617236282496 [label="input
 (9921, 128)" fillcolor=orange]
	139618769086544 -> 139617236280832 [dir=none]
	139617236280832 [label="result1
 (9921, 1)" fillcolor=orange]
	139618769086544 -> 139617236283200 [dir=none]
	139617236283200 [label="result2
 (9921, 1)" fillcolor=orange]
	139618769086544 -> 139617236281920 [dir=none]
	139617236281920 [label="weight
 (128)" fillcolor=orange]
	139618769086544 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618769086832 -> 139618769086544
	139618769086832 -> 139617236280064 [dir=none]
	139617236280064 [label="index
 (9873)" fillcolor=orange]
	139618769086832 -> 139617236280768 [dir=none]
	139617236280768 [label="source
 (9873, 128)" fillcolor=orange]
	139618769086832 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769087264 -> 139618769086832
	139618769087264 -> 139617236281984 [dir=none]
	139617236281984 [label="index
 (9873)" fillcolor=orange]
	139618769087264 -> 139617236280448 [dir=none]
	139617236280448 [label="source
 (9873, 128)" fillcolor=orange]
	139618769087264 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769087552 -> 139618769087264
	139618769087552 -> 139617236280512 [dir=none]
	139617236280512 [label="index
 (9885)" fillcolor=orange]
	139618769087552 -> 139617236282624 [dir=none]
	139617236282624 [label="source
 (9885, 128)" fillcolor=orange]
	139618769087552 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769087744 -> 139618769087552
	139618769087744 -> 139617236283008 [dir=none]
	139617236283008 [label="index
 (9885)" fillcolor=orange]
	139618769087744 -> 139617236281664 [dir=none]
	139617236281664 [label="source
 (9885, 128)" fillcolor=orange]
	139618769087744 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769087984 -> 139618769087744
	139618769087984 -> 139617229355904 [dir=none]
	139617229355904 [label="index
 (9897)" fillcolor=orange]
	139618769087984 -> 139617229353600 [dir=none]
	139617229353600 [label="source
 (9897, 128)" fillcolor=orange]
	139618769087984 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769088320 -> 139618769087984
	139618769088320 -> 139617229353152 [dir=none]
	139617229353152 [label="index
 (9897)" fillcolor=orange]
	139618769088320 -> 139617229354048 [dir=none]
	139617229354048 [label="source
 (9897, 128)" fillcolor=orange]
	139618769088320 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769085200 -> 139618769088320
	139618769085200 -> 139617229353280 [dir=none]
	139617229353280 [label="index
 (9909)" fillcolor=orange]
	139618769085200 -> 139617229353856 [dir=none]
	139617229353856 [label="source
 (9909, 128)" fillcolor=orange]
	139618769085200 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769086784 -> 139618769085200
	139618769086784 -> 139617229354240 [dir=none]
	139617229354240 [label="index
 (9909)" fillcolor=orange]
	139618769086784 -> 139617229354816 [dir=none]
	139617229354816 [label="source
 (9909, 128)" fillcolor=orange]
	139618769086784 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139618769086208 -> 139618769086784
	139618769086208 -> 139617229353920 [dir=none]
	139617229353920 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769086208 -> 139617229354624 [dir=none]
	139617229354624 [label="self
 (9921, 128)" fillcolor=orange]
	139618769086208 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618769085488 -> 139618769086208
	139618769085488 -> 139617229354944 [dir=none]
	139617229354944 [label="result
 (9921, 128)" fillcolor=orange]
	139618769085488 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618769085056 -> 139618769085488
	139618769085056 [label="AddBackward0
------------
alpha: 1"]
	139618769085296 -> 139618769085056
	139618769085296 -> 139617229353472 [dir=none]
	139617229353472 [label="input
 (9921, 128)" fillcolor=orange]
	139618769085296 -> 139617229355712 [dir=none]
	139617229355712 [label="result1
 (9921, 1)" fillcolor=orange]
	139618769085296 -> 139617229356352 [dir=none]
	139617229356352 [label="result2
 (9921, 1)" fillcolor=orange]
	139618769085296 -> 139617229355520 [dir=none]
	139617229355520 [label="weight
 (128)" fillcolor=orange]
	139618769085296 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618769085632 -> 139618769085296
	139618769085632 -> 139617229355008 [dir=none]
	139617229355008 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769085632 -> 139617229356416 [dir=none]
	139617229356416 [label="self
 (9921, 128)" fillcolor=orange]
	139618769085632 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618769086352 -> 139618769085632
	139618769086352 -> 139617229356096 [dir=none]
	139617229356096 [label="result
 (9921, 128)" fillcolor=orange]
	139618769086352 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618769086736 -> 139618769086352
	139618769086736 -> 139617229356032 [dir=none]
	139617229356032 [label="mat1
 (9921, 2)" fillcolor=orange]
	139618769086736 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (9921, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139618769086928 -> 139618769086736
	139617215479232 [label="model.lane_net.input.0.bias
 (128)" fillcolor=lightblue]
	139617215479232 -> 139618769086928
	139618769086928 [label=AccumulateGrad]
	139618769086880 -> 139618769086736
	139618769086880 [label=TBackward]
	139618769087024 -> 139618769086880
	139617215479168 [label="model.lane_net.input.0.weight
 (128, 2)" fillcolor=lightblue]
	139617215479168 -> 139618769087024
	139618769087024 [label=AccumulateGrad]
	139618769085872 -> 139618769085632
	139618769085872 [label=TBackward]
	139618769087216 -> 139618769085872
	139617215395008 [label="model.lane_net.input.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617215395008 -> 139618769087216
	139618769087216 [label=AccumulateGrad]
	139618769085584 -> 139618769085296
	139617215395072 [label="model.lane_net.input.2.norm.weight
 (128)" fillcolor=lightblue]
	139617215395072 -> 139618769085584
	139618769085584 [label=AccumulateGrad]
	139618769085440 -> 139618769085296
	139617215395328 [label="model.lane_net.input.2.norm.bias
 (128)" fillcolor=lightblue]
	139617215395328 -> 139618769085440
	139618769085440 [label=AccumulateGrad]
	139618769085248 -> 139618769085056
	139618769085248 -> 139617200203136 [dir=none]
	139617200203136 [label="input
 (9921, 128)" fillcolor=orange]
	139618769085248 -> 139617200202368 [dir=none]
	139617200202368 [label="result1
 (9921, 1)" fillcolor=orange]
	139618769085248 -> 139617200204416 [dir=none]
	139617200204416 [label="result2
 (9921, 1)" fillcolor=orange]
	139618769085248 -> 139617229354304 [dir=none]
	139617229354304 [label="weight
 (128)" fillcolor=orange]
	139618769085248 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139618769086496 -> 139618769085248
	139618769086496 -> 139617229355072 [dir=none]
	139617229355072 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769086496 -> 139617229356736 [dir=none]
	139617229356736 [label="self
 (9921, 128)" fillcolor=orange]
	139618769086496 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139618769087312 -> 139618769086496
	139618769087312 -> 139617229356800 [dir=none]
	139617229356800 [label="result
 (9921, 128)" fillcolor=orange]
	139618769087312 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618769088032 -> 139618769087312
	139618769088032 -> 139617229355456 [dir=none]
	139617229355456 [label="mat1
 (9921, 2)" fillcolor=orange]
	139618769088032 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (9921, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139618769088176 -> 139618769088032
	139617215395904 [label="model.lane_net._seg.0.bias
 (128)" fillcolor=lightblue]
	139617215395904 -> 139618769088176
	139618769088176 [label=AccumulateGrad]
	139618769088128 -> 139618769088032
	139618769088128 [label=TBackward]
	139618769088224 -> 139618769088128
	139617215395712 [label="model.lane_net._seg.0.weight
 (128, 2)" fillcolor=lightblue]
	139617215395712 -> 139618769088224
	139618769088224 [label=AccumulateGrad]
	139618769086592 -> 139618769086496
	139618769086592 [label=TBackward]
	139618769088368 -> 139618769086592
	139617215396352 [label="model.lane_net._seg.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617215396352 -> 139618769088368
	139618769088368 [label=AccumulateGrad]
	139618769085776 -> 139618769085248
	139617215396416 [label="model.lane_net._seg.2.norm.weight
 (128)" fillcolor=lightblue]
	139617215396416 -> 139618769085776
	139618769085776 [label=AccumulateGrad]
	139618769085728 -> 139618769085248
	139617215396672 [label="model.lane_net._seg.2.norm.bias
 (128)" fillcolor=lightblue]
	139617215396672 -> 139618769085728
	139618769085728 [label=AccumulateGrad]
	139618769084912 -> 139618769086208
	139618769084912 [label=TBackward]
	139618769087456 -> 139618769084912
	139617215397824 [label="model.lane_net.fusion_net.center.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215397824 -> 139618769087456
	139618769087456 [label=AccumulateGrad]
	139618769086160 -> 139618769086784
	139618769086160 -> 139617229356160 [dir=none]
	139617229356160 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769086160 -> 139617229353216 [dir=none]
	139617229353216 [label="self
 (9909, 128)" fillcolor=orange]
	139618769086160 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618769087648 -> 139618769086160
	139618769087648 -> 139617229354752 [dir=none]
	139617229354752 [label="indices[0]
 (9909)" fillcolor=orange]
	139618769087648 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769087648
	139618769084672 -> 139618769086160
	139618769084672 [label=TBackward]
	139618769087504 -> 139618769084672
	139617215722496 [label="model.lane_net.fusion_net.pre1.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215722496 -> 139618769087504
	139618769087504 [label=AccumulateGrad]
	139618769086640 -> 139618769085200
	139618769086640 -> 139617229356992 [dir=none]
	139617229356992 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769086640 -> 139617229355392 [dir=none]
	139617229355392 [label="self
 (9909, 128)" fillcolor=orange]
	139618769086640 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618769085008 -> 139618769086640
	139618769085008 -> 139617229356928 [dir=none]
	139617229356928 [label="indices[0]
 (9909)" fillcolor=orange]
	139618769085008 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769085008
	139618769084864 -> 139618769086640
	139618769084864 [label=TBackward]
	139618769087888 -> 139618769084864
	139617215722560 [label="model.lane_net.fusion_net.suc1.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215722560 -> 139618769087888
	139618769087888 [label=AccumulateGrad]
	139618769084720 -> 139618769088320
	139618769084720 -> 139617229354688 [dir=none]
	139617229354688 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769084720 -> 139618770473472 [dir=none]
	139618770473472 [label="self
 (9897, 128)" fillcolor=orange]
	139618769084720 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618769086016 -> 139618769084720
	139618769086016 -> 139618770474880 [dir=none]
	139618770474880 [label="indices[0]
 (9897)" fillcolor=orange]
	139618769086016 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769086016
	139618769087120 -> 139618769084720
	139618769087120 [label=TBackward]
	139618769088416 -> 139618769087120
	139617215722624 [label="model.lane_net.fusion_net.pre2.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215722624 -> 139618769088416
	139618769088416 [label=AccumulateGrad]
	139618769088272 -> 139618769087984
	139618769088272 -> 139618770475712 [dir=none]
	139618770475712 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769088272 -> 139618770475776 [dir=none]
	139618770475776 [label="self
 (9897, 128)" fillcolor=orange]
	139618769088272 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618769085680 -> 139618769088272
	139618769085680 -> 139618770474688 [dir=none]
	139618770474688 [label="indices[0]
 (9897)" fillcolor=orange]
	139618769085680 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769085680
	139618769088464 -> 139618769088272
	139618769088464 [label=TBackward]
	139617234579520 -> 139618769088464
	139617215722752 [label="model.lane_net.fusion_net.suc2.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215722752 -> 139617234579520
	139617234579520 [label=AccumulateGrad]
	139618769087936 -> 139618769087744
	139618769087936 -> 139618770476800 [dir=none]
	139618770476800 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769087936 -> 139618770473728 [dir=none]
	139618770473728 [label="self
 (9885, 128)" fillcolor=orange]
	139618769087936 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618769088080 -> 139618769087936
	139618769088080 -> 139618770475136 [dir=none]
	139618770475136 [label="indices[0]
 (9885)" fillcolor=orange]
	139618769088080 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769088080
	139617234582400 -> 139618769087936
	139617234582400 [label=TBackward]
	139617234579760 -> 139617234582400
	139617215722944 [label="model.lane_net.fusion_net.pre3.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215722944 -> 139617234579760
	139617234579760 [label=AccumulateGrad]
	139618769087696 -> 139618769087552
	139618769087696 -> 139618770474560 [dir=none]
	139618770474560 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769087696 -> 139618770475840 [dir=none]
	139618770475840 [label="self
 (9885, 128)" fillcolor=orange]
	139618769087696 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618769087840 -> 139618769087696
	139618769087840 -> 139618770473152 [dir=none]
	139618770473152 [label="indices[0]
 (9885)" fillcolor=orange]
	139618769087840 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769087840
	139617234579712 -> 139618769087696
	139617234579712 [label=TBackward]
	139617234582208 -> 139617234579712
	139617215723136 [label="model.lane_net.fusion_net.suc3.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215723136 -> 139617234582208
	139617234582208 [label=AccumulateGrad]
	139618769087408 -> 139618769087264
	139618769087408 -> 139618770476480 [dir=none]
	139618770476480 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769087408 -> 139618770473600 [dir=none]
	139618770473600 [label="self
 (9873, 128)" fillcolor=orange]
	139618769087408 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618769087600 -> 139618769087408
	139618769087600 -> 139618770474816 [dir=none]
	139618770474816 [label="indices[0]
 (9873)" fillcolor=orange]
	139618769087600 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769087600
	139617234579904 -> 139618769087408
	139617234579904 [label=TBackward]
	139617234580528 -> 139617234579904
	139617215723328 [label="model.lane_net.fusion_net.pre4.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215723328 -> 139617234580528
	139617234580528 [label=AccumulateGrad]
	139618769087168 -> 139618769086832
	139618769087168 -> 139618770476224 [dir=none]
	139618770476224 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769087168 -> 139618770476096 [dir=none]
	139618770476096 [label="self
 (9873, 128)" fillcolor=orange]
	139618769087168 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618769087360 -> 139618769087168
	139618769087360 -> 139618770476928 [dir=none]
	139618770476928 [label="indices[0]
 (9873)" fillcolor=orange]
	139618769087360 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618769085488 -> 139618769087360
	139617234580480 -> 139618769087168
	139617234580480 [label=TBackward]
	139617234580768 -> 139617234580480
	139617215723520 [label="model.lane_net.fusion_net.suc4.0.weight
 (128, 128)" fillcolor=lightblue]
	139617215723520 -> 139617234580768
	139617234580768 [label=AccumulateGrad]
	139618769086688 -> 139618769086544
	139617215721536 [label="model.lane_net.fusion_net.group_norm.0.weight
 (128)" fillcolor=lightblue]
	139617215721536 -> 139618769086688
	139618769086688 [label=AccumulateGrad]
	139618769086400 -> 139618769086544
	139617215721664 [label="model.lane_net.fusion_net.group_norm.0.bias
 (128)" fillcolor=lightblue]
	139617215721664 -> 139618769086400
	139618769086400 [label=AccumulateGrad]
	139618769086256 -> 139618769085968
	139618769086256 [label=TBackward]
	139618769087072 -> 139618769086256
	139617215722048 [label="model.lane_net.fusion_net.linear_w_group_norm.0.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617215722048 -> 139618769087072
	139618769087072 [label=AccumulateGrad]
	139618769085920 -> 139618769085536
	139617215722112 [label="model.lane_net.fusion_net.linear_w_group_norm.0.norm.weight
 (128)" fillcolor=lightblue]
	139617215722112 -> 139618769085920
	139618769085920 [label=AccumulateGrad]
	139618769085824 -> 139618769085536
	139617215722368 [label="model.lane_net.fusion_net.linear_w_group_norm.0.norm.bias
 (128)" fillcolor=lightblue]
	139617215722368 -> 139618769085824
	139618769085824 [label=AccumulateGrad]
	139618769085488 -> 139618769085392
	139618769085152 -> 139618769084816
	139618769085152 [label=TBackward]
	139618769086064 -> 139618769085152
	139617215723712 [label="model.lane_net.fusion_net.center.1.weight
 (128, 128)" fillcolor=lightblue]
	139617215723712 -> 139618769086064
	139618769086064 [label=AccumulateGrad]
	139618769084768 -> 139618769084576
	139618769084768 -> 139618770475904 [dir=none]
	139618770475904 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769084768 -> 139618770476672 [dir=none]
	139618770476672 [label="self
 (9909, 128)" fillcolor=orange]
	139618769084768 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618769086976 -> 139618769084768
	139618769086976 -> 139618770476608 [dir=none]
	139618770476608 [label="indices[0]
 (9909)" fillcolor=orange]
	139618769086976 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618769086976
	139618769084960 -> 139618769084768
	139618769084960 [label=TBackward]
	139618769086112 -> 139618769084960
	139617215725120 [label="model.lane_net.fusion_net.pre1.1.weight
 (128, 128)" fillcolor=lightblue]
	139617215725120 -> 139618769086112
	139618769086112 [label=AccumulateGrad]
	139618769084528 -> 139617237341856
	139618769084528 -> 139618770473856 [dir=none]
	139618770473856 [label="mat2
 (128, 128)" fillcolor=orange]
	139618769084528 -> 139618770474048 [dir=none]
	139618770474048 [label="self
 (9909, 128)" fillcolor=orange]
	139618769084528 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618769085344 -> 139618769084528
	139618769085344 -> 139618770475520 [dir=none]
	139618770475520 [label="indices[0]
 (9909)" fillcolor=orange]
	139618769085344 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618769085344
	139618769085104 -> 139618769084528
	139618769085104 [label=TBackward]
	139618769086448 -> 139618769085104
	139617215725184 [label="model.lane_net.fusion_net.suc1.1.weight
 (128, 128)" fillcolor=lightblue]
	139617215725184 -> 139618769086448
	139618769086448 [label=AccumulateGrad]
	139617237340320 -> 139618771070592
	139617237340320 -> 139618770473920 [dir=none]
	139618770473920 [label="mat2
 (128, 128)" fillcolor=orange]
	139617237340320 -> 139618770475584 [dir=none]
	139618770475584 [label="self
 (9897, 128)" fillcolor=orange]
	139617237340320 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618769084624 -> 139617237340320
	139618769084624 -> 139618770475648 [dir=none]
	139618770475648 [label="indices[0]
 (9897)" fillcolor=orange]
	139618769084624 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618769084624
	139618769084480 -> 139617237340320
	139618769084480 [label=TBackward]
	139617234580816 -> 139618769084480
	139617215725248 [label="model.lane_net.fusion_net.pre2.1.weight
 (128, 128)" fillcolor=lightblue]
	139617215725248 -> 139617234580816
	139617234580816 [label=AccumulateGrad]
	139618771070400 -> 139618771070208
	139618771070400 -> 139618770476288 [dir=none]
	139618770476288 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771070400 -> 139618770473024 [dir=none]
	139618770473024 [label="self
 (9897, 128)" fillcolor=orange]
	139618771070400 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618771070784 -> 139618771070400
	139618771070784 -> 139617236073792 [dir=none]
	139617236073792 [label="indices[0]
 (9897)" fillcolor=orange]
	139618771070784 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618771070784
	139617234580864 -> 139618771070400
	139617234580864 [label=TBackward]
	139617234580960 -> 139617234580864
	139617216069696 [label="model.lane_net.fusion_net.suc2.1.weight
 (128, 128)" fillcolor=lightblue]
	139617216069696 -> 139617234580960
	139617234580960 [label=AccumulateGrad]
	139618771070112 -> 139618771070016
	139618771070112 -> 139617236070656 [dir=none]
	139617236070656 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771070112 -> 139617236074368 [dir=none]
	139617236074368 [label="self
 (9885, 128)" fillcolor=orange]
	139618771070112 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618771070256 -> 139618771070112
	139618771070256 -> 139617236071232 [dir=none]
	139617236071232 [label="indices[0]
 (9885)" fillcolor=orange]
	139618771070256 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618771070256
	139617234581488 -> 139618771070112
	139617234581488 [label=TBackward]
	139617234581200 -> 139617234581488
	139617216069888 [label="model.lane_net.fusion_net.pre3.1.weight
 (128, 128)" fillcolor=lightblue]
	139617216069888 -> 139617234581200
	139617234581200 [label=AccumulateGrad]
	139618771069824 -> 139618771069104
	139618771069824 -> 139617236071360 [dir=none]
	139617236071360 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771069824 -> 139617236071936 [dir=none]
	139617236071936 [label="self
 (9885, 128)" fillcolor=orange]
	139618771069824 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618771070064 -> 139618771069824
	139618771070064 -> 139617236072640 [dir=none]
	139617236072640 [label="indices[0]
 (9885)" fillcolor=orange]
	139618771070064 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618771070064
	139617234581056 -> 139618771069824
	139617234581056 [label=TBackward]
	139617234581344 -> 139617234581056
	139617216070080 [label="model.lane_net.fusion_net.suc3.1.weight
 (128, 128)" fillcolor=lightblue]
	139617216070080 -> 139617234581344
	139617234581344 [label=AccumulateGrad]
	139618771068960 -> 139618771068672
	139618771068960 -> 139617236073216 [dir=none]
	139617236073216 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068960 -> 139617236071296 [dir=none]
	139617236071296 [label="self
 (9873, 128)" fillcolor=orange]
	139618771068960 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618771069536 -> 139618771068960
	139618771069536 -> 139617236071616 [dir=none]
	139617236071616 [label="indices[0]
 (9873)" fillcolor=orange]
	139618771069536 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618771069536
	139617234581248 -> 139618771068960
	139617234581248 [label=TBackward]
	139617234581440 -> 139617234581248
	139617216070272 [label="model.lane_net.fusion_net.pre4.1.weight
 (128, 128)" fillcolor=lightblue]
	139617216070272 -> 139617234581440
	139617234581440 [label=AccumulateGrad]
	139618771068480 -> 139618771070880
	139618771068480 -> 139617236072960 [dir=none]
	139617236072960 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068480 -> 139617236071808 [dir=none]
	139617236071808 [label="self
 (9873, 128)" fillcolor=orange]
	139618771068480 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618771068768 -> 139618771068480
	139618771068768 -> 139617236072768 [dir=none]
	139617236072768 [label="indices[0]
 (9873)" fillcolor=orange]
	139618771068768 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771069776 -> 139618771068768
	139617234581392 -> 139618771068480
	139617234581392 [label=TBackward]
	139617234581632 -> 139617234581392
	139617216070464 [label="model.lane_net.fusion_net.suc4.1.weight
 (128, 128)" fillcolor=lightblue]
	139617216070464 -> 139617234581632
	139617234581632 [label=AccumulateGrad]
	139618771070736 -> 139618771070688
	139617215723904 [label="model.lane_net.fusion_net.group_norm.1.weight
 (128)" fillcolor=lightblue]
	139617215723904 -> 139618771070736
	139618771070736 [label=AccumulateGrad]
	139618771070544 -> 139618771070688
	139617215724288 [label="model.lane_net.fusion_net.group_norm.1.bias
 (128)" fillcolor=lightblue]
	139617215724288 -> 139618771070544
	139618771070544 [label=AccumulateGrad]
	139618771070448 -> 139618771070160
	139618771070448 [label=TBackward]
	139618771067952 -> 139618771070448
	139617215724672 [label="model.lane_net.fusion_net.linear_w_group_norm.1.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617215724672 -> 139618771067952
	139618771067952 [label=AccumulateGrad]
	139618771069968 -> 139618771069872
	139617215724736 [label="model.lane_net.fusion_net.linear_w_group_norm.1.norm.weight
 (128)" fillcolor=lightblue]
	139617215724736 -> 139618771069968
	139618771069968 [label=AccumulateGrad]
	139618771069920 -> 139618771069872
	139617215724992 [label="model.lane_net.fusion_net.linear_w_group_norm.1.norm.bias
 (128)" fillcolor=lightblue]
	139617215724992 -> 139618771069920
	139618771069920 [label=AccumulateGrad]
	139618771069776 -> 139618771069728
	139618771069632 -> 139618771069440
	139618771069632 [label=TBackward]
	139618771070304 -> 139618771069632
	139617216070656 [label="model.lane_net.fusion_net.center.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216070656 -> 139618771070304
	139618771070304 [label=AccumulateGrad]
	139618771069392 -> 139618771069296
	139618771069392 -> 139617236073920 [dir=none]
	139617236073920 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771069392 -> 139617236071488 [dir=none]
	139617236071488 [label="self
 (9909, 128)" fillcolor=orange]
	139618771069392 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618771070928 -> 139618771069392
	139618771070928 -> 139617236074240 [dir=none]
	139617236074240 [label="indices[0]
 (9909)" fillcolor=orange]
	139618771070928 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771070928
	139618771069488 -> 139618771069392
	139618771069488 [label=TBackward]
	139618771070352 -> 139618771069488
	139617216071872 [label="model.lane_net.fusion_net.pre1.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216071872 -> 139618771070352
	139618771070352 [label=AccumulateGrad]
	139618771069248 -> 139618771069152
	139618771069248 -> 139617236072896 [dir=none]
	139617236072896 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771069248 -> 139617236073600 [dir=none]
	139617236073600 [label="self
 (9909, 128)" fillcolor=orange]
	139618771069248 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139618771069680 -> 139618771069248
	139618771069680 -> 139617236073152 [dir=none]
	139617236073152 [label="indices[0]
 (9909)" fillcolor=orange]
	139618771069680 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771069680
	139618771069584 -> 139618771069248
	139618771069584 [label=TBackward]
	139618771070640 -> 139618771069584
	139617216071936 [label="model.lane_net.fusion_net.suc1.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216071936 -> 139618771070640
	139618771070640 [label=AccumulateGrad]
	139618771069056 -> 139618771068912
	139618771069056 -> 139617235330048 [dir=none]
	139617235330048 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771069056 -> 139617235332096 [dir=none]
	139617235332096 [label="self
 (9897, 128)" fillcolor=orange]
	139618771069056 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618771069344 -> 139618771069056
	139618771069344 -> 139617235331456 [dir=none]
	139617235331456 [label="indices[0]
 (9897)" fillcolor=orange]
	139618771069344 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771069344
	139618771069200 -> 139618771069056
	139618771069200 [label=TBackward]
	139617234581776 -> 139618771069200
	139617216072000 [label="model.lane_net.fusion_net.pre2.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072000 -> 139617234581776
	139617234581776 [label=AccumulateGrad]
	139618771068864 -> 139618771068720
	139618771068864 -> 139617235330432 [dir=none]
	139617235330432 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068864 -> 139617235329856 [dir=none]
	139617235329856 [label="self
 (9897, 128)" fillcolor=orange]
	139618771068864 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139618771069008 -> 139618771068864
	139618771069008 -> 139617235331712 [dir=none]
	139617235331712 [label="indices[0]
 (9897)" fillcolor=orange]
	139618771069008 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771069008
	139617234581824 -> 139618771068864
	139617234581824 [label=TBackward]
	139617234581920 -> 139617234581824
	139617216072128 [label="model.lane_net.fusion_net.suc2.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072128 -> 139617234581920
	139617234581920 [label=AccumulateGrad]
	139618771068576 -> 139618771068384
	139618771068576 -> 139617235329600 [dir=none]
	139617235329600 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068576 -> 139617235329344 [dir=none]
	139617235329344 [label="self
 (9885, 128)" fillcolor=orange]
	139618771068576 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618771068816 -> 139618771068576
	139618771068816 -> 139617235329472 [dir=none]
	139617235329472 [label="indices[0]
 (9885)" fillcolor=orange]
	139618771068816 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771068816
	139617234580720 -> 139618771068576
	139617234580720 [label=TBackward]
	139617234582304 -> 139617234580720
	139617216072320 [label="model.lane_net.fusion_net.pre3.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072320 -> 139617234582304
	139617234582304 [label=AccumulateGrad]
	139618771068096 -> 139618771067664
	139618771068096 -> 139617235331584 [dir=none]
	139617235331584 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068096 -> 139617235329536 [dir=none]
	139617235329536 [label="self
 (9885, 128)" fillcolor=orange]
	139618771068096 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139618771068432 -> 139618771068096
	139618771068432 -> 139617235330304 [dir=none]
	139617235330304 [label="indices[0]
 (9885)" fillcolor=orange]
	139618771068432 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771068432
	139617234582160 -> 139618771068096
	139617234582160 [label=TBackward]
	139617234582640 -> 139617234582160
	139617216072512 [label="model.lane_net.fusion_net.suc3.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072512 -> 139617234582640
	139617234582640 [label=AccumulateGrad]
	139618771067472 -> 139618771068624
	139618771067472 -> 139617235332416 [dir=none]
	139617235332416 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771067472 -> 139617235331264 [dir=none]
	139617235331264 [label="self
 (9873, 128)" fillcolor=orange]
	139618771067472 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618771067760 -> 139618771067472
	139618771067760 -> 139617235332288 [dir=none]
	139617235332288 [label="indices[0]
 (9873)" fillcolor=orange]
	139618771067760 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771067760
	139617234583168 -> 139618771067472
	139617234583168 [label=TBackward]
	139617234582928 -> 139617234583168
	139617216072704 [label="model.lane_net.fusion_net.pre4.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072704 -> 139617234582928
	139617234582928 [label=AccumulateGrad]
	139618771068528 -> 139618771068240
	139618771068528 -> 139617235332224 [dir=none]
	139617235332224 [label="mat2
 (128, 128)" fillcolor=orange]
	139618771068528 -> 139617235332736 [dir=none]
	139617235332736 [label="self
 (9873, 128)" fillcolor=orange]
	139618771068528 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139618771067520 -> 139618771068528
	139618771067520 -> 139617235331328 [dir=none]
	139617235331328 [label="indices[0]
 (9873)" fillcolor=orange]
	139618771067520 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139618771067328 -> 139618771067520
	139617234582784 -> 139618771068528
	139617234582784 [label=TBackward]
	139617234583072 -> 139617234582784
	139617216072896 [label="model.lane_net.fusion_net.suc4.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216072896 -> 139617234583072
	139617234583072 [label=AccumulateGrad]
	139618771068192 -> 139618771068144
	139617216070848 [label="model.lane_net.fusion_net.group_norm.2.weight
 (128)" fillcolor=lightblue]
	139617216070848 -> 139618771068192
	139618771068192 [label=AccumulateGrad]
	139618771068000 -> 139618771068144
	139617216071040 [label="model.lane_net.fusion_net.group_norm.2.bias
 (128)" fillcolor=lightblue]
	139617216071040 -> 139618771068000
	139618771068000 [label=AccumulateGrad]
	139618771067856 -> 139618771067616
	139618771067856 [label=TBackward]
	139618771068336 -> 139618771067856
	139617216071424 [label="model.lane_net.fusion_net.linear_w_group_norm.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139617216071424 -> 139618771068336
	139618771068336 [label=AccumulateGrad]
	139618771067568 -> 139618771067376
	139617216071488 [label="model.lane_net.fusion_net.linear_w_group_norm.2.norm.weight
 (128)" fillcolor=lightblue]
	139617216071488 -> 139618771067568
	139618771067568 [label=AccumulateGrad]
	139618771067424 -> 139618771067376
	139617216071744 [label="model.lane_net.fusion_net.linear_w_group_norm.2.norm.bias
 (128)" fillcolor=lightblue]
	139617216071744 -> 139618771067424
	139618771067424 [label=AccumulateGrad]
	139618771067328 -> 139618771067280
	139618771066992 -> 139617236085392
	139618771066992 [label=TBackward]
	139618771067040 -> 139618771066992
	139617216289664 [label="model.actor2lane_attention.lane_meta.linear.weight
 (128, 134)" fillcolor=lightblue]
	139617216289664 -> 139618771067040
	139618771067040 [label=AccumulateGrad]
	139617236085440 -> 139617236086016
	139617216289728 [label="model.actor2lane_attention.lane_meta.norm.weight
 (128)" fillcolor=lightblue]
	139617216289728 -> 139617236085440
	139617236085440 [label=AccumulateGrad]
	139617236086112 -> 139617236086016
	139617216289984 [label="model.actor2lane_attention.lane_meta.norm.bias
 (128)" fillcolor=lightblue]
	139617216289984 -> 139617236086112
	139617236086112 [label=AccumulateGrad]
	139617236084864 -> 139617236084672
	139617236084864 [label=TBackward]
	139617236085632 -> 139617236084864
	139617216909440 [label="model.actor2lane_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216909440 -> 139617236085632
	139617236085632 [label=AccumulateGrad]
	139617236086736 -> 139617236086592
	139617236086736 -> 139617235331968 [dir=none]
	139617235331968 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617236086736 -> 139617235332800 [dir=none]
	139617235332800 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236086736 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236083136 -> 139617236086736
	139617216910976 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617216910976 -> 139617236083136
	139617236083136 [label=AccumulateGrad]
	139617236083952 -> 139617236086736
	139617236083952 -> 139617219426048 [dir=none]
	139617219426048 [label="result
 (156865, 128)" fillcolor=orange]
	139617236083952 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618771067712 -> 139617236083952
	139618771067712 -> 139617219426176 [dir=none]
	139617219426176 [label="mat1
 (156865, 384)" fillcolor=orange]
	139618771067712 -> 139617219425408 [dir=none]
	139617219425408 [label="mat2
 (384, 128)" fillcolor=orange]
	139618771067712 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618771068288 -> 139618771067712
	139617216910656 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216910656 -> 139618771068288
	139618771068288 [label=AccumulateGrad]
	139618771067088 -> 139618771067712
	139618771067088 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617234583360 -> 139618771067088
	139617234583360 -> 139617235330560 [dir=none]
	139617235330560 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234583360 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617234579808 -> 139617234583360
	139617234579808 -> 139617235330816 [dir=none]
	139617235330816 [label="result
 (68, 128)" fillcolor=orange]
	139617234579808 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234579952 -> 139617234579808
	139617234579952 -> 139617235330624 [dir=none]
	139617235330624 [label="mat1
 (68, 128)" fillcolor=orange]
	139617234579952 -> 139617235329792 [dir=none]
	139617235329792 [label="mat2
 (128, 128)" fillcolor=orange]
	139617234579952 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617234580336 -> 139617234579952
	139617216290304 [label="model.actor2lane_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216290304 -> 139617234580336
	139617234580336 [label=AccumulateGrad]
	139618568972032 -> 139617234579952
	139617234580144 -> 139617234579952
	139617234580144 [label=TBackward]
	139617234580576 -> 139617234580144
	139617216290240 [label="model.actor2lane_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216290240 -> 139617234580576
	139617234580576 [label=AccumulateGrad]
	139617234582976 -> 139618771067088
	139617234582976 -> 139617219424960 [dir=none]
	139617219424960 [label="result
 (156865, 128)" fillcolor=orange]
	139617234582976 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234581584 -> 139617234582976
	139617234581584 -> 139617219425984 [dir=none]
	139617219425984 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617234581584 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617234581152 -> 139617234581584
	139617216910080 [label="model.actor2lane_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216910080 -> 139617234581152
	139617234581152 [label=AccumulateGrad]
	139617234580624 -> 139617234581584
	139617234580624 [label=TBackward]
	139617234581104 -> 139617234580624
	139617216909952 [label="model.actor2lane_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617216909952 -> 139617234581104
	139617234581104 [label=AccumulateGrad]
	139617234583408 -> 139618771067088
	139617234583408 -> 139617235331776 [dir=none]
	139617235331776 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234583408 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617236083520 -> 139617234583408
	139618771066944 -> 139618771067712
	139618771066944 [label=TBackward]
	139617234580912 -> 139618771066944
	139617216910528 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617216910528 -> 139617234580912
	139617234580912 [label=AccumulateGrad]
	139617236083328 -> 139617236086736
	139617236083328 [label=TBackward]
	139618771068048 -> 139617236083328
	139617216910784 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216910784 -> 139618771068048
	139618771068048 [label=AccumulateGrad]
	139617236086544 -> 139617236086400
	139617216911552 [label="model.actor2lane_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617216911552 -> 139617236086544
	139617236086544 [label=AccumulateGrad]
	139617236086496 -> 139617236086400
	139617216911424 [label="model.actor2lane_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617216911424 -> 139617236086496
	139617236086496 [label=AccumulateGrad]
	139617236086160 -> 139617236086064
	139617236086160 [label=TBackward]
	139617236086688 -> 139617236086160
	139617216911168 [label="model.actor2lane_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617216911168 -> 139617236086688
	139617236086688 [label=AccumulateGrad]
	139617236086016 -> 139617236085872
	139617236085728 -> 139617236085680
	139617236085728 [label=TBackward]
	139618771067184 -> 139617236085728
	139617216912640 [label="model.actor2lane_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216912640 -> 139618771067184
	139618771067184 [label=AccumulateGrad]
	139617236085248 -> 139617236084912
	139617236085248 -> 139617235332992 [dir=none]
	139617235332992 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617236085248 -> 139617235332032 [dir=none]
	139617235332032 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236085248 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618771067808 -> 139617236085248
	139617216750400 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617216750400 -> 139618771067808
	139618771067808 [label=AccumulateGrad]
	139617236085584 -> 139617236085248
	139617236085584 -> 139617219425088 [dir=none]
	139617219425088 [label="result
 (156865, 128)" fillcolor=orange]
	139617236085584 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236086352 -> 139617236085584
	139617236086352 -> 139617219425920 [dir=none]
	139617219425920 [label="mat1
 (156865, 384)" fillcolor=orange]
	139617236086352 -> 139617219424896 [dir=none]
	139617219424896 [label="mat2
 (384, 128)" fillcolor=orange]
	139617236086352 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139617236086448 -> 139617236086352
	139617216750080 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216750080 -> 139617236086448
	139617236086448 [label=AccumulateGrad]
	139617236086640 -> 139617236086352
	139617236086640 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617234581728 -> 139617236086640
	139617234581728 -> 139617219426560 [dir=none]
	139617219426560 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234581728 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617234581968 -> 139617234581728
	139617234581968 -> 139617219425728 [dir=none]
	139617219425728 [label="result
 (68, 128)" fillcolor=orange]
	139617234581968 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234582112 -> 139617234581968
	139617234582112 -> 139617226233984 [dir=none]
	139617226233984 [label="mat1
 (68, 128)" fillcolor=orange]
	139617234582112 -> 139617226232192 [dir=none]
	139617226232192 [label="mat2
 (128, 128)" fillcolor=orange]
	139617234582112 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617234582352 -> 139617234582112
	139617216911936 [label="model.actor2lane_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216911936 -> 139617234582352
	139617234582352 [label=AccumulateGrad]
	139618568972032 -> 139617234582112
	139617234582256 -> 139617234582112
	139617234582256 [label=TBackward]
	139617234582448 -> 139617234582256
	139617216912000 [label="model.actor2lane_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216912000 -> 139617234582448
	139617234582448 [label=AccumulateGrad]
	139617234579856 -> 139617236086640
	139617234579856 -> 139617226233472 [dir=none]
	139617226233472 [label="result
 (156865, 128)" fillcolor=orange]
	139617234579856 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234581536 -> 139617234579856
	139617234581536 -> 139617226233216 [dir=none]
	139617226233216 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617234581536 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617234582736 -> 139617234581536
	139617216913280 [label="model.actor2lane_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216913280 -> 139617234582736
	139617234582736 [label=AccumulateGrad]
	139617234582496 -> 139617234581536
	139617234582496 [label=TBackward]
	139617234582688 -> 139617234582496
	139617216913152 [label="model.actor2lane_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617216913152 -> 139617234582688
	139617234582688 [label=AccumulateGrad]
	139617234582016 -> 139617236086640
	139617234582016 -> 139617226235072 [dir=none]
	139617226235072 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234582016 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617236085536 -> 139617234582016
	139617236085920 -> 139617236086352
	139617236085920 [label=TBackward]
	139617234582544 -> 139617236085920
	139617216749952 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617216749952 -> 139617234582544
	139617234582544 [label=AccumulateGrad]
	139617236085488 -> 139617236085248
	139617236085488 [label=TBackward]
	139617236085968 -> 139617236085488
	139617216750208 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216750208 -> 139617236085968
	139617236085968 [label=AccumulateGrad]
	139617236084816 -> 139617236084624
	139617216750976 [label="model.actor2lane_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617216750976 -> 139617236084816
	139617236084816 [label=AccumulateGrad]
	139617236084768 -> 139617236084624
	139617216750848 [label="model.actor2lane_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617216750848 -> 139617236084768
	139617236084768 [label=AccumulateGrad]
	139617236084432 -> 139617236084384
	139617236084432 [label=TBackward]
	139617236085152 -> 139617236084432
	139617216750592 [label="model.actor2lane_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617216750592 -> 139617236085152
	139617236085152 [label=AccumulateGrad]
	139617236084336 -> 139617236084192
	139617236084096 -> 139617236084048
	139617236084096 [label=TBackward]
	139617236084576 -> 139617236084096
	139617216752064 [label="model.actor2lane_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216752064 -> 139617236084576
	139617236084576 [label=AccumulateGrad]
	139617236083712 -> 139617236083568
	139617236083712 -> 139617226234880 [dir=none]
	139617226234880 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617236083712 -> 139617226235456 [dir=none]
	139617226235456 [label="mat2
 (128, 128)" fillcolor=orange]
	139617236083712 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236083808 -> 139617236083712
	139617217617984 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617217617984 -> 139617236083808
	139617236083808 [label=AccumulateGrad]
	139617236084000 -> 139617236083712
	139617236084000 -> 139617226232128 [dir=none]
	139617226232128 [label="result
 (156865, 128)" fillcolor=orange]
	139617236084000 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236085344 -> 139617236084000
	139617236085344 -> 139617226233536 [dir=none]
	139617226233536 [label="mat1
 (156865, 384)" fillcolor=orange]
	139617236085344 -> 139617226235392 [dir=none]
	139617226235392 [label="mat2
 (384, 128)" fillcolor=orange]
	139617236085344 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139617236084720 -> 139617236085344
	139617216753280 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216753280 -> 139617236084720
	139617236084720 [label=AccumulateGrad]
	139617236084240 -> 139617236085344
	139617236084240 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617234583216 -> 139617236084240
	139617234583216 -> 139617226234176 [dir=none]
	139617226234176 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234583216 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617234583312 -> 139617234583216
	139617234583312 -> 139617226233600 [dir=none]
	139617226233600 [label="result
 (68, 128)" fillcolor=orange]
	139617234583312 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234583504 -> 139617234583312
	139617234583504 -> 139617226234816 [dir=none]
	139617226234816 [label="mat1
 (68, 128)" fillcolor=orange]
	139617234583504 -> 139617226233920 [dir=none]
	139617226233920 [label="mat2
 (128, 128)" fillcolor=orange]
	139617234583504 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617234580000 -> 139617234583504
	139617216751360 [label="model.actor2lane_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216751360 -> 139617234580000
	139617234580000 [label=AccumulateGrad]
	139618568972032 -> 139617234583504
	139617234582592 -> 139617234583504
	139617234582592 [label=TBackward]
	139617234580048 -> 139617234582592
	139617216751424 [label="model.actor2lane_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617216751424 -> 139617234580048
	139617234580048 [label=AccumulateGrad]
	139617234582064 -> 139617236084240
	139617234582064 -> 139617226232064 [dir=none]
	139617226232064 [label="result
 (156865, 128)" fillcolor=orange]
	139617234582064 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617234583024 -> 139617234582064
	139617234583024 -> 139617226235648 [dir=none]
	139617226235648 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617234583024 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617234580240 -> 139617234583024
	139617216752704 [label="model.actor2lane_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617216752704 -> 139617234580240
	139617234580240 [label=AccumulateGrad]
	139617234582880 -> 139617234583024
	139617234582880 [label=TBackward]
	139617234583120 -> 139617234582880
	139617216752576 [label="model.actor2lane_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617216752576 -> 139617234583120
	139617234583120 [label=AccumulateGrad]
	139617234579568 -> 139617236084240
	139617234579568 -> 139617226234240 [dir=none]
	139617226234240 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234579568 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617236083904 -> 139617234579568
	139617234581296 -> 139617236085344
	139617234581296 [label=TBackward]
	139617234580192 -> 139617234581296
	139617216753152 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617216753152 -> 139617234580192
	139617234580192 [label=AccumulateGrad]
	139617236083856 -> 139617236083712
	139617236083856 [label=TBackward]
	139617236085008 -> 139617236083856
	139617216753408 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617216753408 -> 139617236085008
	139617236085008 [label=AccumulateGrad]
	139617236083472 -> 139617236083280
	139617217618496 [label="model.actor2lane_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617217618496 -> 139617236083472
	139617236083472 [label=AccumulateGrad]
	139617236083424 -> 139617236083280
	139617217618368 [label="model.actor2lane_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617217618368 -> 139617236083424
	139617236083424 [label=AccumulateGrad]
	139617236083040 -> 139617236082992
	139617236083040 [label=TBackward]
	139617236083664 -> 139617236083040
	139617217618112 [label="model.actor2lane_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617217618112 -> 139617236083664
	139617236083664 [label=AccumulateGrad]
	139617236082944 -> 139617236082800
	139617219257872 -> 139617219257728
	139617219257872 [label=TBackward]
	139617236083232 -> 139617219257872
	139617217619584 [label="model.actor2lane_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217619584 -> 139617236083232
	139617236083232 [label=AccumulateGrad]
	139617219257008 -> 139617219466048
	139617219257008 -> 139617226232000 [dir=none]
	139617226232000 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617219257008 -> 139617226232448 [dir=none]
	139617226232448 [label="mat2
 (128, 128)" fillcolor=orange]
	139617219257008 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617219257152 -> 139617219257008
	139617217621120 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617217621120 -> 139617219257152
	139617219257152 [label=AccumulateGrad]
	139617219257680 -> 139617219257008
	139617219257680 -> 139617226234560 [dir=none]
	139617226234560 [label="result
 (156865, 128)" fillcolor=orange]
	139617219257680 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617236084288 -> 139617219257680
	139617236084288 -> 139617226232320 [dir=none]
	139617226232320 [label="mat1
 (156865, 384)" fillcolor=orange]
	139617236084288 -> 139617226235712 [dir=none]
	139617226235712 [label="mat2
 (384, 128)" fillcolor=orange]
	139617236084288 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139617236083376 -> 139617236084288
	139617217620800 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217620800 -> 139617236083376
	139617236083376 [label=AccumulateGrad]
	139617236082848 -> 139617236084288
	139617236082848 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617234581008 -> 139617236082848
	139617234581008 -> 139617226235584 [dir=none]
	139617226235584 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234581008 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617231589824 -> 139617234581008
	139617231589824 -> 139617226233344 [dir=none]
	139617226233344 [label="result
 (68, 128)" fillcolor=orange]
	139617231589824 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231590400 -> 139617231589824
	139617231590400 -> 139619639493056 [dir=none]
	139619639493056 [label="mat1
 (68, 128)" fillcolor=orange]
	139617231590400 -> 139619639494400 [dir=none]
	139619639494400 [label="mat2
 (128, 128)" fillcolor=orange]
	139617231590400 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617231590736 -> 139617231590400
	139617217618880 [label="model.actor2lane_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217618880 -> 139617231590736
	139617231590736 [label=AccumulateGrad]
	139618568972032 -> 139617231590400
	139617231590592 -> 139617231590400
	139617231590592 [label=TBackward]
	139617231590832 -> 139617231590592
	139617217618944 [label="model.actor2lane_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217618944 -> 139617231590832
	139617231590832 [label=AccumulateGrad]
	139617234583456 -> 139617236082848
	139617234583456 -> 139619639493952 [dir=none]
	139619639493952 [label="result
 (156865, 128)" fillcolor=orange]
	139617234583456 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231589632 -> 139617234583456
	139617231589632 -> 139619639492928 [dir=none]
	139619639492928 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617231589632 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617231592512 -> 139617231589632
	139617217620224 [label="model.actor2lane_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217620224 -> 139617231592512
	139617231592512 [label=AccumulateGrad]
	139617231590976 -> 139617231589632
	139617231590976 [label=TBackward]
	139617231591744 -> 139617231590976
	139617217620096 [label="model.actor2lane_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617217620096 -> 139617231591744
	139617231591744 [label=AccumulateGrad]
	139617234579616 -> 139617236082848
	139617234579616 -> 139619639495232 [dir=none]
	139619639495232 [label="indices[0]
 (156865)" fillcolor=orange]
	139617234579616 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617219257440 -> 139617234579616
	139617234582832 -> 139617236084288
	139617234582832 [label=TBackward]
	139617234581872 -> 139617234582832
	139617217620672 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617217620672 -> 139617234581872
	139617234581872 [label=AccumulateGrad]
	139617219257248 -> 139617219257008
	139617219257248 [label=TBackward]
	139617234583264 -> 139617219257248
	139617217620928 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617217620928 -> 139617234583264
	139617234583264 [label=AccumulateGrad]
	139617219465808 -> 139618564225344
	139617217621696 [label="model.actor2lane_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617217621696 -> 139617219465808
	139617219465808 [label=AccumulateGrad]
	139618564226880 -> 139618564225344
	139617217621568 [label="model.actor2lane_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617217621568 -> 139618564226880
	139618564226880 [label=AccumulateGrad]
	139618564227024 -> 139618564226976
	139618564227024 [label=TBackward]
	139617219256960 -> 139618564227024
	139617217621312 [label="model.actor2lane_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617217621312 -> 139617219256960
	139617219256960 [label=AccumulateGrad]
	139618564226928 -> 139618564226736
	139618564226160 -> 139618564226496
	139618564226160 [label=TBackward]
	139617236082896 -> 139618564226160
	139617217466816 [label="model.lane2actor_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217466816 -> 139617236082896
	139617236082896 [label=AccumulateGrad]
	139618564225728 -> 139618564225776
	139618564225728 -> 139617230162112 [dir=none]
	139617230162112 [label="result
 (156865, 128)" fillcolor=orange]
	139618564225728 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617219256624 -> 139618564225728
	139617219256624 -> 139619639493312 [dir=none]
	139619639493312 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617219256624 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139618564226640 -> 139617219256624
	139617217468288 [label="model.lane2actor_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217468288 -> 139618564226640
	139618564226640 [label=AccumulateGrad]
	139618564226448 -> 139617219256624
	139618564226448 [label=TBackward]
	139618564226832 -> 139618564226448
	139617217468160 [label="model.lane2actor_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617217468160 -> 139618564226832
	139618564226832 [label=AccumulateGrad]
	139618564225968 -> 139618564225776
	139618564225968 -> 139619639495040 [dir=none]
	139619639495040 [label="indices[0]
 (156865)" fillcolor=orange]
	139618564225968 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139618568973184 -> 139618564225968
	139618564223136 -> 139618564225824
	139618564223136 [label=TBackward]
	139617236083616 -> 139618564223136
	139617217468736 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617217468736 -> 139617236083616
	139617236083616 [label=AccumulateGrad]
	139618564225440 -> 139618568972464
	139618564225440 [label=TBackward]
	139618564226784 -> 139618564225440
	139617217468992 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617217468992 -> 139618564226784
	139618564226784 [label=AccumulateGrad]
	139618568971072 -> 139618568970880
	139617217469760 [label="model.lane2actor_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617217469760 -> 139618568971072
	139618568971072 [label=AccumulateGrad]
	139618568971648 -> 139618568970880
	139617217469632 [label="model.lane2actor_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617217469632 -> 139618568971648
	139618568971648 [label=AccumulateGrad]
	139618568970688 -> 139617229479360
	139618568970688 [label=TBackward]
	139618568972608 -> 139618568970688
	139617217469376 [label="model.lane2actor_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617217469376 -> 139618568972608
	139618568972608 [label=AccumulateGrad]
	139618568972032 -> 139617229478400
	139617229478976 -> 139617232629824
	139617229478976 [label=TBackward]
	139617229478784 -> 139617229478976
	139617217823168 [label="model.lane2actor_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217823168 -> 139617229478784
	139617229478784 [label=AccumulateGrad]
	139617232632656 -> 139617232631648
	139617232632656 -> 139619639496064 [dir=none]
	139619639496064 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617232632656 -> 139619639493824 [dir=none]
	139619639493824 [label="mat2
 (128, 128)" fillcolor=orange]
	139617232632656 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617229479504 -> 139617232632656
	139617217824704 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617217824704 -> 139617229479504
	139617229479504 [label=AccumulateGrad]
	139617232633328 -> 139617232632656
	139617232633328 -> 139619639493184 [dir=none]
	139619639493184 [label="result
 (156865, 128)" fillcolor=orange]
	139617232633328 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618568970544 -> 139617232633328
	139618568970544 -> 139619639496192 [dir=none]
	139619639496192 [label="mat1
 (156865, 384)" fillcolor=orange]
	139618568970544 -> 139619639495744 [dir=none]
	139619639495744 [label="mat2
 (384, 128)" fillcolor=orange]
	139618568970544 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618568974000 -> 139618568970544
	139617217824384 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217824384 -> 139618568974000
	139618568974000 [label=AccumulateGrad]
	139618564224816 -> 139618568970544
	139618564224816 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139618564224576 -> 139618564224816
	139618564224576 -> 139619639496000 [dir=none]
	139619639496000 [label="indices[0]
 (156865)" fillcolor=orange]
	139618564224576 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617231593040 -> 139618564224576
	139617231593040 -> 139619639494080 [dir=none]
	139619639494080 [label="result
 (9921, 128)" fillcolor=orange]
	139617231593040 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231592704 -> 139617231593040
	139617231592704 -> 139619639495168 [dir=none]
	139619639495168 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617231592704 -> 139619639494848 [dir=none]
	139619639494848 [label="mat2
 (128, 128)" fillcolor=orange]
	139617231592704 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617231593328 -> 139617231592704
	139617217470144 [label="model.lane2actor_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217470144 -> 139617231593328
	139617231593328 [label=AccumulateGrad]
	139618564226544 -> 139617231592704
	139617231592560 -> 139617231592704
	139617231592560 [label=TBackward]
	139617231589584 -> 139617231592560
	139617217470208 [label="model.lane2actor_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217470208 -> 139617231589584
	139617231589584 [label=AccumulateGrad]
	139618564226688 -> 139618564224816
	139618564226688 -> 139619639495872 [dir=none]
	139619639495872 [label="result
 (156865, 128)" fillcolor=orange]
	139618564226688 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231589680 -> 139618564226688
	139617231589680 -> 139619639495680 [dir=none]
	139619639495680 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617231589680 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617231590160 -> 139617231589680
	139617217823808 [label="model.lane2actor_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217823808 -> 139617231590160
	139617231590160 [label=AccumulateGrad]
	139617231589728 -> 139617231589680
	139617231589728 [label=TBackward]
	139617231590016 -> 139617231589728
	139617217823680 [label="model.lane2actor_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617217823680 -> 139617231590016
	139617231590016 [label=AccumulateGrad]
	139618564226208 -> 139618564224816
	139618564226208 -> 139618408323072 [dir=none]
	139618408323072 [label="indices[0]
 (156865)" fillcolor=orange]
	139618564226208 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617232633568 -> 139618564226208
	139618564225248 -> 139618568970544
	139618564225248 [label=TBackward]
	139618564225104 -> 139618564225248
	139617217824256 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617217824256 -> 139618564225104
	139618564225104 [label=AccumulateGrad]
	139617232632848 -> 139617232632656
	139617232632848 [label=TBackward]
	139618564226304 -> 139617232632848
	139617217824512 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617217824512 -> 139618564226304
	139618564226304 [label=AccumulateGrad]
	139617232631792 -> 139617232630928
	139617217825280 [label="model.lane2actor_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617217825280 -> 139617232631792
	139617232631792 [label=AccumulateGrad]
	139617232631360 -> 139617232630928
	139617217825152 [label="model.lane2actor_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617217825152 -> 139617232631360
	139617232631360 [label=AccumulateGrad]
	139617232630304 -> 139617232630448
	139617232630304 [label=TBackward]
	139617232631888 -> 139617232630304
	139617217824896 [label="model.lane2actor_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617217824896 -> 139617232631888
	139617232631888 [label=AccumulateGrad]
	139617232630064 -> 139617232629920
	139617232632032 -> 139617232633424
	139617232632032 [label=TBackward]
	139618568972224 -> 139617232632032
	139617217826368 [label="model.lane2actor_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217826368 -> 139618568972224
	139618568972224 [label=AccumulateGrad]
	139617232633280 -> 139617232633088
	139617232633280 -> 139618408323328 [dir=none]
	139618408323328 [label="mat1
 (156865, 128)" fillcolor=orange]
	139617232633280 -> 139618408324608 [dir=none]
	139618408324608 [label="mat2
 (128, 128)" fillcolor=orange]
	139617232633280 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618568971840 -> 139617232633280
	139617201403008 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617201403008 -> 139618568971840
	139618568971840 [label=AccumulateGrad]
	139617232633616 -> 139617232633280
	139617232633616 -> 139619639494336 [dir=none]
	139619639494336 [label="result
 (156865, 128)" fillcolor=orange]
	139617232633616 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232631264 -> 139617232633616
	139617232631264 -> 139619639494528 [dir=none]
	139619639494528 [label="mat1
 (156865, 384)" fillcolor=orange]
	139617232631264 -> 139619639496576 [dir=none]
	139619639496576 [label="mat2
 (384, 128)" fillcolor=orange]
	139617232631264 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139617232631456 -> 139617232631264
	139617201402688 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201402688 -> 139617232631456
	139617232631456 [label=AccumulateGrad]
	139617232632176 -> 139617232631264
	139617232632176 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617231590352 -> 139617232632176
	139617231590352 -> 139618408322304 [dir=none]
	139618408322304 [label="indices[0]
 (156865)" fillcolor=orange]
	139617231590352 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617231590496 -> 139617231590352
	139617231590496 -> 139618408324096 [dir=none]
	139618408324096 [label="result
 (9921, 128)" fillcolor=orange]
	139617231590496 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231590640 -> 139617231590496
	139617231590640 -> 139618408324544 [dir=none]
	139618408324544 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617231590640 -> 139618408323840 [dir=none]
	139618408323840 [label="mat2
 (128, 128)" fillcolor=orange]
	139617231590640 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617231590880 -> 139617231590640
	139617217825664 [label="model.lane2actor_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617217825664 -> 139617231590880
	139617231590880 [label=AccumulateGrad]
	139618564226544 -> 139617231590640
	139617231590688 -> 139617231590640
	139617231590688 [label=TBackward]
	139617231591024 -> 139617231590688
	139617217825728 [label="model.lane2actor_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617217825728 -> 139617231591024
	139617231591024 [label=AccumulateGrad]
	139617231592896 -> 139617232632176
	139617231592896 -> 139618408321920 [dir=none]
	139618408321920 [label="result
 (156865, 128)" fillcolor=orange]
	139617231592896 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231590304 -> 139617231592896
	139617231590304 -> 139618408321792 [dir=none]
	139618408321792 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617231590304 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617231591504 -> 139617231590304
	139617201402112 [label="model.lane2actor_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201402112 -> 139617231591504
	139617231591504 [label=AccumulateGrad]
	139617231591168 -> 139617231590304
	139617231591168 [label=TBackward]
	139617231591360 -> 139617231591168
	139617201401984 [label="model.lane2actor_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617201401984 -> 139617231591360
	139617231591360 [label=AccumulateGrad]
	139617231590112 -> 139617232632176
	139617231590112 -> 139617232221632 [dir=none]
	139617232221632 [label="indices[0]
 (156865)" fillcolor=orange]
	139617231590112 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617232632752 -> 139617231590112
	139617232632512 -> 139617232631264
	139617232632512 [label=TBackward]
	139617231591264 -> 139617232632512
	139617201402560 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617201402560 -> 139617231591264
	139617231591264 [label=AccumulateGrad]
	139617232632896 -> 139617232633280
	139617232632896 [label=TBackward]
	139617232630160 -> 139617232632896
	139617201402816 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617201402816 -> 139617232630160
	139617232630160 [label=AccumulateGrad]
	139617232631552 -> 139617232630208
	139617201403584 [label="model.lane2actor_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617201403584 -> 139617232631552
	139617232631552 [label=AccumulateGrad]
	139617232630976 -> 139617232630208
	139617201403456 [label="model.lane2actor_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617201403456 -> 139617232630976
	139617232630976 [label=AccumulateGrad]
	139618562225392 -> 139618562226400
	139618562225392 [label=TBackward]
	139617232633664 -> 139618562225392
	139617201403200 [label="model.lane2actor_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617201403200 -> 139617232633664
	139617232633664 [label=AccumulateGrad]
	139618562226640 -> 139618562225728
	139618562227360 -> 139618562228128
	139618562227360 [label=TBackward]
	139618562227792 -> 139618562227360
	139617201404672 [label="model.lane2actor_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617201404672 -> 139618562227792
	139618562227792 [label=AccumulateGrad]
	139618562227408 -> 139618562225200
	139618562227408 -> 139618408323200 [dir=none]
	139618408323200 [label="mat1
 (156865, 128)" fillcolor=orange]
	139618562227408 -> 139618408321984 [dir=none]
	139618408321984 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562227408 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562227648 -> 139618562227408
	139617201226048 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617201226048 -> 139618562227648
	139618562227648 [label=AccumulateGrad]
	139618562225776 -> 139618562227408
	139618562225776 -> 139617231383616 [dir=none]
	139617231383616 [label="result
 (156865, 128)" fillcolor=orange]
	139618562225776 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617232631072 -> 139618562225776
	139617232631072 -> 139617231381696 [dir=none]
	139617231381696 [label="mat1
 (156865, 384)" fillcolor=orange]
	139617232631072 -> 139617231382464 [dir=none]
	139617231382464 [label="mat2
 (384, 128)" fillcolor=orange]
	139617232631072 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139617232631168 -> 139617232631072
	139617201225792 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201225792 -> 139617232631168
	139617232631168 [label=AccumulateGrad]
	139617232630544 -> 139617232631072
	139617232630544 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617231591984 -> 139617232630544
	139617231591984 -> 139618408324224 [dir=none]
	139618408324224 [label="indices[0]
 (156865)" fillcolor=orange]
	139617231591984 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139617231592272 -> 139617231591984
	139617231592272 -> 139618408324864 [dir=none]
	139618408324864 [label="result
 (9921, 128)" fillcolor=orange]
	139617231592272 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231592752 -> 139617231592272
	139617231592752 -> 139618408323712 [dir=none]
	139618408323712 [label="mat1
 (9921, 128)" fillcolor=orange]
	139617231592752 -> 139618408322048 [dir=none]
	139618408322048 [label="mat2
 (128, 128)" fillcolor=orange]
	139617231592752 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617231592992 -> 139617231592752
	139617201403968 [label="model.lane2actor_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201403968 -> 139617231592992
	139617231592992 [label=AccumulateGrad]
	139618564226544 -> 139617231592752
	139617231592848 -> 139617231592752
	139617231592848 [label=TBackward]
	139617220575296 -> 139617231592848
	139617201404032 [label="model.lane2actor_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617201404032 -> 139617220575296
	139617220575296 [label=AccumulateGrad]
	139617231590544 -> 139617232630544
	139617231590544 -> 139618408323584 [dir=none]
	139618408323584 [label="result
 (156865, 128)" fillcolor=orange]
	139617231590544 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617231591840 -> 139617231590544
	139617231591840 -> 139617231382848 [dir=none]
	139617231382848 [label="mat1
 (156865, 2)" fillcolor=orange]
	139617231591840 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617231592080 -> 139617231591840
	139617201405312 [label="model.lane2actor_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201405312 -> 139617231592080
	139617231592080 [label=AccumulateGrad]
	139617220577888 -> 139617231591840
	139617220577888 [label=TBackward]
	139617220578560 -> 139617220577888
	139617201405184 [label="model.lane2actor_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617201405184 -> 139617220578560
	139617220578560 [label=AccumulateGrad]
	139617231589968 -> 139617232630544
	139617231589968 -> 139617231383744 [dir=none]
	139617231383744 [label="indices[0]
 (156865)" fillcolor=orange]
	139617231589968 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139618562227936 -> 139617231589968
	139617231590256 -> 139617232631072
	139617231590256 [label=TBackward]
	139617231592416 -> 139617231590256
	139617201405760 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617201405760 -> 139617231592416
	139617231592416 [label=AccumulateGrad]
	139618562228032 -> 139618562227408
	139618562228032 [label=TBackward]
	139617232632272 -> 139618562228032
	139617201225856 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617201225856 -> 139617232632272
	139617232632272 [label=AccumulateGrad]
	139618562225152 -> 139618562226928
	139617201226624 [label="model.lane2actor_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617201226624 -> 139618562225152
	139618562225152 [label=AccumulateGrad]
	139618562227072 -> 139618562226928
	139617201226496 [label="model.lane2actor_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617201226496 -> 139618562227072
	139618562227072 [label=AccumulateGrad]
	139618562226208 -> 139618562225584
	139618562226208 [label=TBackward]
	139618562227504 -> 139618562226208
	139617201226240 [label="model.lane2actor_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617201226240 -> 139618562227504
	139618562227504 [label=AccumulateGrad]
	139618562225824 -> 139618562225056
	139618562224864 -> 139618562224960
	139618562224864 [label=TBackward]
	139618562227312 -> 139618562224864
	139617201228224 [label="model.actor2actor_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617201228224 -> 139618562227312
	139618562227312 [label=AccumulateGrad]
	139618562224288 -> 139617229451168
	139618562224288 -> 139617231382400 [dir=none]
	139617231382400 [label="mat1
 (590, 128)" fillcolor=orange]
	139618562224288 -> 139617231383552 [dir=none]
	139617231383552 [label="mat2
 (128, 128)" fillcolor=orange]
	139618562224288 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139618562224576 -> 139618562224288
	139617200799808 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617200799808 -> 139618562224576
	139618562224576 [label=AccumulateGrad]
	139618562224624 -> 139618562224288
	139618562224624 -> 139617231380992 [dir=none]
	139617231380992 [label="result
 (590, 128)" fillcolor=orange]
	139618562224624 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618562226736 -> 139618562224624
	139618562226736 -> 139617231382912 [dir=none]
	139617231382912 [label="mat1
 (590, 384)" fillcolor=orange]
	139618562226736 -> 139617231383296 [dir=none]
	139617231383296 [label="mat2
 (384, 128)" fillcolor=orange]
	139618562226736 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618562226544 -> 139618562226736
	139617201229440 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201229440 -> 139618562226544
	139618562226544 [label=AccumulateGrad]
	139618562225488 -> 139618562226736
	139618562225488 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617231590448 -> 139618562225488
	139617231590448 -> 139617231381056 [dir=none]
	139617231381056 [label="indices[0]
 (590)" fillcolor=orange]
	139617231590448 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617220578176 -> 139617231590448
	139617220578176 -> 139617231381952 [dir=none]
	139617231381952 [label="result
 (68, 128)" fillcolor=orange]
	139617220578176 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220575392 -> 139617220578176
	139617220575392 -> 139617231384384 [dir=none]
	139617231384384 [label="mat1
 (68, 128)" fillcolor=orange]
	139617220575392 -> 139617231072768 [dir=none]
	139617231072768 [label="mat2
 (128, 128)" fillcolor=orange]
	139617220575392 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617220575488 -> 139617220575392
	139617201227648 [label="model.actor2actor_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201227648 -> 139617220575488
	139617220575488 [label=AccumulateGrad]
	139617229449248 -> 139617220575392
	139617220575440 -> 139617220575392
	139617220575440 [label=TBackward]
	139617220575536 -> 139617220575440
	139617201227584 [label="model.actor2actor_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617201227584 -> 139617220575536
	139617220575536 [label=AccumulateGrad]
	139617220578848 -> 139618562225488
	139617220578848 -> 139617231069376 [dir=none]
	139617231069376 [label="result
 (590, 128)" fillcolor=orange]
	139617220578848 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220578320 -> 139617220578848
	139617220578320 -> 139617231069696 [dir=none]
	139617231069696 [label="mat1
 (590, 2)" fillcolor=orange]
	139617220578320 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617220575728 -> 139617220578320
	139617201228864 [label="model.actor2actor_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617201228864 -> 139617220575728
	139617220575728 [label=AccumulateGrad]
	139617220575584 -> 139617220578320
	139617220575584 [label=TBackward]
	139617220575680 -> 139617220575584
	139617201228736 [label="model.actor2actor_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617201228736 -> 139617220575680
	139617220575680 [label=AccumulateGrad]
	139617220575968 -> 139618562225488
	139617220575968 -> 139617231070336 [dir=none]
	139617231070336 [label="indices[0]
 (590)" fillcolor=orange]
	139617220575968 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139618562224768 -> 139617220575968
	139617231591552 -> 139618562226736
	139617231591552 [label=TBackward]
	139617220575632 -> 139617231591552
	139617201229312 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617201229312 -> 139617220575632
	139617220575632 [label=AccumulateGrad]
	139618562224480 -> 139618562224288
	139618562224480 [label=TBackward]
	139617231591600 -> 139618562224480
	139617201229568 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617201229568 -> 139617231591600
	139617231591600 [label=AccumulateGrad]
	139617229447808 -> 139617229450304
	139617200800320 [label="model.actor2actor_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617200800320 -> 139617229447808
	139617229447808 [label=AccumulateGrad]
	139617229450688 -> 139617229450304
	139617200800192 [label="model.actor2actor_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617200800192 -> 139617229450688
	139617229450688 [label=AccumulateGrad]
	139617229449680 -> 139617229449872
	139617229449680 [label=TBackward]
	139617229450496 -> 139617229449680
	139617200799936 [label="model.actor2actor_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617200799936 -> 139617229450496
	139617229450496 [label=AccumulateGrad]
	139617229449248 -> 139617229449152
	139617229447952 -> 139617219697344
	139617229447952 [label=TBackward]
	139617229450400 -> 139617229447952
	139617200801408 [label="model.actor2actor_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200801408 -> 139617229450400
	139617229450400 [label=AccumulateGrad]
	139617219697104 -> 139617219695712
	139617219697104 -> 139617231070144 [dir=none]
	139617231070144 [label="mat1
 (590, 128)" fillcolor=orange]
	139617219697104 -> 139617231070272 [dir=none]
	139617231070272 [label="mat2
 (128, 128)" fillcolor=orange]
	139617219697104 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617219697920 -> 139617219697104
	139617200802944 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617200802944 -> 139617219697920
	139617219697920 [label=AccumulateGrad]
	139617219697632 -> 139617219697104
	139617219697632 -> 139617231069568 [dir=none]
	139617231069568 [label="result
 (590, 128)" fillcolor=orange]
	139617219697632 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617229451072 -> 139617219697632
	139617229451072 -> 139617231071488 [dir=none]
	139617231071488 [label="mat1
 (590, 384)" fillcolor=orange]
	139617229451072 -> 139617231070784 [dir=none]
	139617231070784 [label="mat2
 (384, 128)" fillcolor=orange]
	139617229451072 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618562224384 -> 139617229451072
	139617200802624 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200802624 -> 139618562224384
	139618562224384 [label=AccumulateGrad]
	139618562225344 -> 139617229451072
	139618562225344 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617220575872 -> 139618562225344
	139617220575872 -> 139617231070656 [dir=none]
	139617231070656 [label="indices[0]
 (590)" fillcolor=orange]
	139617220575872 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617220576016 -> 139617220575872
	139617220576016 -> 139617231071040 [dir=none]
	139617231071040 [label="result
 (68, 128)" fillcolor=orange]
	139617220576016 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220576112 -> 139617220576016
	139617220576112 -> 139617231069888 [dir=none]
	139617231069888 [label="mat1
 (68, 128)" fillcolor=orange]
	139617220576112 -> 139617231071360 [dir=none]
	139617231071360 [label="mat2
 (128, 128)" fillcolor=orange]
	139617220576112 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617220576208 -> 139617220576112
	139617200800704 [label="model.actor2actor_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200800704 -> 139617220576208
	139617220576208 [label=AccumulateGrad]
	139618570611632 -> 139617220576112
	139617220576160 -> 139617220576112
	139617220576160 [label=TBackward]
	139617220576256 -> 139617220576160
	139617200800768 [label="model.actor2actor_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200800768 -> 139617220576256
	139617220576256 [label=AccumulateGrad]
	139617220575344 -> 139618562225344
	139617220575344 -> 139617231069312 [dir=none]
	139617231069312 [label="result
 (590, 128)" fillcolor=orange]
	139617220575344 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220575824 -> 139617220575344
	139617220575824 -> 139617231070464 [dir=none]
	139617231070464 [label="mat1
 (590, 2)" fillcolor=orange]
	139617220575824 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617220576544 -> 139617220575824
	139617200802048 [label="model.actor2actor_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200802048 -> 139617220576544
	139617220576544 [label=AccumulateGrad]
	139617220576304 -> 139617220575824
	139617220576304 [label=TBackward]
	139617220576400 -> 139617220576304
	139617200801920 [label="model.actor2actor_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617200801920 -> 139617220576400
	139617220576400 [label=AccumulateGrad]
	139617220577024 -> 139618562225344
	139617220577024 -> 139617231072064 [dir=none]
	139617231072064 [label="indices[0]
 (590)" fillcolor=orange]
	139617220577024 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617219694800 -> 139617220577024
	139618562227168 -> 139617229451072
	139618562227168 [label=TBackward]
	139617220576352 -> 139618562227168
	139617200802496 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617200802496 -> 139617220576352
	139617220576352 [label=AccumulateGrad]
	139617229448528 -> 139617219697104
	139617229448528 [label=TBackward]
	139617229448336 -> 139617229448528
	139617200802752 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617200802752 -> 139617229448336
	139617229448336 [label=AccumulateGrad]
	139617219696000 -> 139618570610432
	139617200803520 [label="model.actor2actor_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617200803520 -> 139617219696000
	139617219696000 [label=AccumulateGrad]
	139617219695280 -> 139618570610432
	139617200803392 [label="model.actor2actor_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617200803392 -> 139617219695280
	139617219695280 [label=AccumulateGrad]
	139618570612064 -> 139618570612304
	139618570612064 [label=TBackward]
	139617219696432 -> 139618570612064
	139617200803136 [label="model.actor2actor_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617200803136 -> 139617219696432
	139617219696432 [label=AccumulateGrad]
	139618570611632 -> 139618570611440
	139618570610960 -> 139618570610000
	139618570610960 [label=TBackward]
	139617229449488 -> 139618570610960
	139617200673600 [label="model.actor2actor_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200673600 -> 139617229449488
	139617229449488 [label=AccumulateGrad]
	139618570608896 -> 139617236113248
	139618570608896 -> 139617231071872 [dir=none]
	139617231071872 [label="mat1
 (590, 128)" fillcolor=orange]
	139618570608896 -> 139617231071104 [dir=none]
	139617231071104 [label="mat2
 (128, 128)" fillcolor=orange]
	139618570608896 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617219696720 -> 139618570608896
	139617200675136 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617200675136 -> 139617219696720
	139617219696720 [label=AccumulateGrad]
	139618570610192 -> 139618570608896
	139618570610192 -> 139617231071680 [dir=none]
	139617231071680 [label="result
 (590, 128)" fillcolor=orange]
	139618570610192 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618570611200 -> 139618570610192
	139618570611200 -> 139617231071424 [dir=none]
	139617231071424 [label="mat1
 (590, 384)" fillcolor=orange]
	139618570611200 -> 139617231072320 [dir=none]
	139617231072320 [label="mat2
 (384, 128)" fillcolor=orange]
	139618570611200 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618570608704 -> 139618570611200
	139617200674816 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200674816 -> 139618570608704
	139618570608704 [label=AccumulateGrad]
	139618570611152 -> 139618570611200
	139618570611152 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617220576688 -> 139618570611152
	139617220576688 -> 139617231072192 [dir=none]
	139617231072192 [label="indices[0]
 (590)" fillcolor=orange]
	139617220576688 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617220576784 -> 139617220576688
	139617220576784 -> 139617231072448 [dir=none]
	139617231072448 [label="result
 (68, 128)" fillcolor=orange]
	139617220576784 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220576880 -> 139617220576784
	139617220576880 -> 139617231072000 [dir=none]
	139617231072000 [label="mat1
 (68, 128)" fillcolor=orange]
	139617220576880 -> 139617231072640 [dir=none]
	139617231072640 [label="mat2
 (128, 128)" fillcolor=orange]
	139617220576880 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617220576976 -> 139617220576880
	139617200672896 [label="model.actor2actor_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200672896 -> 139617220576976
	139617220576976 [label=AccumulateGrad]
	139618677206176 -> 139617220576880
	139617220576928 -> 139617220576880
	139617220576928 [label=TBackward]
	139617220577072 -> 139617220576928
	139617200672960 [label="model.actor2actor_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200672960 -> 139617220577072
	139617220577072 [label=AccumulateGrad]
	139617220576064 -> 139618570611152
	139617220576064 -> 139617231070720 [dir=none]
	139617231070720 [label="result
 (590, 128)" fillcolor=orange]
	139617220576064 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220576640 -> 139617220576064
	139617220576640 -> 139617231072256 [dir=none]
	139617231072256 [label="mat1
 (590, 2)" fillcolor=orange]
	139617220576640 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617220577264 -> 139617220576640
	139617200674240 [label="model.actor2actor_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200674240 -> 139617220577264
	139617220577264 [label=AccumulateGrad]
	139617220577120 -> 139617220576640
	139617220577120 [label=TBackward]
	139617220577216 -> 139617220577120
	139617200674112 [label="model.actor2actor_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617200674112 -> 139617220577216
	139617220577216 [label=AccumulateGrad]
	139617220577984 -> 139618570611152
	139617220577984 -> 139617231073216 [dir=none]
	139617231073216 [label="indices[0]
 (590)" fillcolor=orange]
	139617220577984 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139618570609568 -> 139617220577984
	139617220575776 -> 139618570611200
	139617220575776 [label=TBackward]
	139617220577168 -> 139617220575776
	139617200674688 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617200674688 -> 139617220577168
	139617220577168 [label=AccumulateGrad]
	139618570609760 -> 139618570608896
	139618570609760 [label=TBackward]
	139618570611824 -> 139618570609760
	139617200674944 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617200674944 -> 139618570611824
	139618570611824 [label=AccumulateGrad]
	139617236113824 -> 139617236111616
	139617200675712 [label="model.actor2actor_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617200675712 -> 139617236113824
	139617236113824 [label=AccumulateGrad]
	139617236113344 -> 139617236111616
	139617200675584 [label="model.actor2actor_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617200675584 -> 139617236113344
	139617236113344 [label=AccumulateGrad]
	139618677206560 -> 139618677206752
	139618677206560 [label=TBackward]
	139617236113680 -> 139618677206560
	139617200675328 [label="model.actor2actor_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617200675328 -> 139617236113680
	139617236113680 [label=AccumulateGrad]
	139618677206176 -> 139618677205936
	139618677205552 -> 139618677204880
	139618677205552 [label=TBackward]
	139618677203296 -> 139618677205552
	139617200676800 [label="model.actor2actor_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200676800 -> 139618677203296
	139618677203296 [label=AccumulateGrad]
	139618677203584 -> 139617219601600
	139618677203584 -> 139617231072960 [dir=none]
	139617231072960 [label="mat1
 (590, 128)" fillcolor=orange]
	139618677203584 -> 139617231072576 [dir=none]
	139617231072576 [label="mat2
 (128, 128)" fillcolor=orange]
	139618677203584 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617236113776 -> 139618677203584
	139617202857472 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139617202857472 -> 139617236113776
	139617236113776 [label=AccumulateGrad]
	139618677205120 -> 139618677203584
	139618677205120 -> 139617231072832 [dir=none]
	139617231072832 [label="result
 (590, 128)" fillcolor=orange]
	139618677205120 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139618677206368 -> 139618677205120
	139618677206368 -> 139617231071936 [dir=none]
	139617231071936 [label="mat1
 (590, 384)" fillcolor=orange]
	139618677206368 -> 139617231070208 [dir=none]
	139617231070208 [label="mat2
 (384, 128)" fillcolor=orange]
	139618677206368 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139618570610384 -> 139618677206368
	139617202857152 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617202857152 -> 139618570610384
	139618570610384 [label=AccumulateGrad]
	139618570609184 -> 139618677206368
	139618570609184 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139617220577408 -> 139618570609184
	139617220577408 -> 139617231072896 [dir=none]
	139617231072896 [label="indices[0]
 (590)" fillcolor=orange]
	139617220577408 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139617220577504 -> 139617220577408
	139617220577504 -> 139617231069824 [dir=none]
	139617231069824 [label="result
 (68, 128)" fillcolor=orange]
	139617220577504 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220577600 -> 139617220577504
	139617220577600 -> 139617231070080 [dir=none]
	139617231070080 [label="mat1
 (68, 128)" fillcolor=orange]
	139617220577600 -> 139617231073152 [dir=none]
	139617231073152 [label="mat2
 (128, 128)" fillcolor=orange]
	139617220577600 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139617220577696 -> 139617220577600
	139617200676096 [label="model.actor2actor_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617200676096 -> 139617220577696
	139617220577696 [label=AccumulateGrad]
	139619599445632 -> 139617220577600
	139617220577648 -> 139617220577600
	139617220577648 [label=TBackward]
	139617220577744 -> 139617220577648
	139617200676160 [label="model.actor2actor_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139617200676160 -> 139617220577744
	139617220577744 [label=AccumulateGrad]
	139617220576832 -> 139618570609184
	139617220576832 -> 139617231072512 [dir=none]
	139617231072512 [label="result
 (590, 128)" fillcolor=orange]
	139617220576832 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139617220577360 -> 139617220576832
	139617220577360 -> 139617231071616 [dir=none]
	139617231071616 [label="mat1
 (590, 2)" fillcolor=orange]
	139617220577360 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139617220578032 -> 139617220577360
	139617202856576 [label="model.actor2actor_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139617202856576 -> 139617220578032
	139617220578032 [label=AccumulateGrad]
	139617220577792 -> 139617220577360
	139617220577792 [label=TBackward]
	139617220577936 -> 139617220577792
	139617202856448 [label="model.actor2actor_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139617202856448 -> 139617220577936
	139617220577936 [label=AccumulateGrad]
	139617220576448 -> 139618570609184
	139617220576448 -> 139617231072128 [dir=none]
	139617231072128 [label="indices[0]
 (590)" fillcolor=orange]
	139617220576448 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139618677204448 -> 139617220576448
	139617220576592 -> 139618677206368
	139617220576592 [label=TBackward]
	139617220577840 -> 139617220576592
	139617202857024 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139617202857024 -> 139617220577840
	139617220577840 [label=AccumulateGrad]
	139618677204688 -> 139618677203584
	139618677204688 [label=TBackward]
	139618677205744 -> 139618677204688
	139617202857280 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139617202857280 -> 139618677205744
	139618677205744 [label=AccumulateGrad]
	139617219600448 -> 139617219602128
	139617202858048 [label="model.actor2actor_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139617202858048 -> 139617219600448
	139617219600448 [label=AccumulateGrad]
	139618677203392 -> 139617219602128
	139617202857920 [label="model.actor2actor_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139617202857920 -> 139618677203392
	139618677203392 [label=AccumulateGrad]
	139617219601360 -> 139619599443568
	139617219601360 [label=TBackward]
	139617219601840 -> 139617219601360
	139617202857664 [label="model.actor2actor_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139617202857664 -> 139617219601840
	139617219601840 [label=AccumulateGrad]
	139619599445632 -> 139619599445872
	139617231536288 -> 139618452676816
	139617231536288 [label=TBackward]
	139619597247344 -> 139617231536288
	139617202858240 [label="model._mlp.0.weight
 (128, 128)" fillcolor=lightblue]
	139617202858240 -> 139619597247344
	139619597247344 [label=AccumulateGrad]
	139618452677536 -> 139618452679888
	139618452677536 [label=TBackward]
	139617231537392 -> 139618452677536
	139617202858752 [label="model._mlp.2.weight
 (128, 128)" fillcolor=lightblue]
	139617202858752 -> 139617231537392
	139617231537392 [label=AccumulateGrad]
	139618452677728 -> 139618681379280
	139618452677728 [label=TBackward]
	139617231536864 -> 139618452677728
	139617202859264 [label="model._mlp.4.weight
 (48, 128)" fillcolor=lightblue]
	139617202859264 -> 139617231536864
	139617231536864 [label=AccumulateGrad]
	139618681380816 -> 139617218720128
	139617231070976 [label="
 (1, 48)" fillcolor=darkolivegreen3]
	139618681379280 -> 139617231070976
	139617231070976 -> 139617218720128 [style=dotted]
}
